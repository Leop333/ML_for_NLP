{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теория"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<абзац про присяжных>\n",
    "\n",
    "### где сегодня используются ансамбли\n",
    "- Везде, где можно применять классические алгоритмы (ансамбли дают более точные результаты)\n",
    "- Поисковые системы (ранжирование реультатов)\n",
    "- Компьютерное зрение (распознавание объектов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Идея\n",
    "Если взять несколько методов научить их последовательно исправлять ошибки друг друга, качество такой системы будет выше, чем каждого из методов по отдельности.\n",
    "\n",
    "Лучше, если алгоритмы неустойчивы к аномалиям в данных: поэтому для ансамблей берут Регрессию и Деревья Решений.\n",
    "\n",
    "### Как собрать ансамбль?\n",
    "- ансамбль собирают из supervised-алгоритмов, потому что важно знать, в чем/где ошибаются модели\n",
    "- в плане последовательности можно собрать как угодно, но опытным путем нашлись три способа: *стэкинг*, *бэггинг* и *бустинг*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея: на одних и тех же данных обучаем несколько разных алгоритмов (например, классификации). Передаем реультаты финальному, он принимает решение (обычно это регрессия).\n",
    "\n",
    "<img alt=\"\" width=\"900\" height=\"600\" src=\"https://miro.medium.com/max/1892/0*GHYCJIjkkrP5ZgPh.png\">\n",
    "\n",
    "[ссылка на картинку](https://medium.com/@rrfd/boosting-bagging-and-stacking-ensemble-methods-with-sklearn-and-mlens-a455c0c982de)\n",
    "\n",
    "*С добавлением новых моделей в ансамбль, мы не повысим качество предсказаний*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея: несколько раз тренируем один и тот же алгоритм на разных подвыборках из данных. В результате усредняем ответы и определяем финальный. \n",
    "<img alt=\"\" width=\"700\" height=\"400\" src=\"https://miro.medium.com/max/1920/1*DFHUbdz6EyOuMYP4pDnFlw.jpeg\">\n",
    "\n",
    "[ссылка на картинку](https://medium.com/@rrfd/boosting-bagging-and-stacking-ensemble-methods-with-sklearn-and-mlens-a455c0c982de)\n",
    "\n",
    "Самый популярный бэггинг - это [Random Forest](https://ru.wikipedia.org/wiki/Random_forest) (набор решающих деревьев)<br>\n",
    "Бэггинг -- эффективный метод, если у вас небольшой датасет.<br>\n",
    "[Чем бэггинг отличается от кросс-валидации?](https://www.kaggle.com/questions-and-answers/120778)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея: обучаем алгоритмы последовательно, каждый следующий уделяет внимание ошибкам предыдущего. Продолжаем, пока метрики не станут хорошими\n",
    "\n",
    "<img alt=\"Boosting procedure\" src=\"https://pluralsight2.imgix.net/guides/a9a5ff4e-b617-4afe-b27b-d96793defa87_6.jpg\">\n",
    "\n",
    "[ссылка на картинку](https://www.pluralsight.com/guides/ensemble-methods:-bagging-versus-boosting)\n",
    "\n",
    "[статья про популярные типы бустинга](https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### разница между бэггингом и бустингом\n",
    "\n",
    "<img alt=\"Bagging, Boosting\" width=\"700\" height=\"400\" src=\"https://pluralsight2.imgix.net/guides/81232a78-2e99-4ccc-ba8e-8cd873625fdf_2.jpg\">\n",
    "\n",
    "**Когда что использовать?**\n",
    "- Бэггинг, если у данных высокая дисперсия\n",
    "- Бустинг, если данные неравномерно распределены\n",
    "\n",
    "**Bagging VS Boosting**\n",
    "\n",
    "Нет одноначного ответа, что лучше, это зависит от задачи и данных. Если модель хорошо работает на обучающих данных, но плохо на тестовых, то в данных может быть высокая диспрерсия. Если модель плохо работает на обучающих данных, стоит проверить распределение классов/параметров.\n",
    "Предварительно стоит проаналиировать данные, затем попробовать несколько моделей, постепенно изменяя параметры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Грузим датасет Wine. Будем предсказывать происхождение вина по его химическим характеристикам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## подготовим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(wine['data'], columns=wine['feature_names'])\n",
    "target = wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  \n",
       "0                          3.92   1065.0  \n",
       "1                          3.40   1050.0  \n",
       "2                          3.17   1185.0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(target.shape)\n",
    "\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделение на обучающую и тестовую выборку\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сначала обучим одно решающее дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_y_pred = tree_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        17\n",
      "           1       0.96      0.88      0.92        25\n",
      "           2       0.86      1.00      0.92        12\n",
      "\n",
      "    accuracy                           0.93        54\n",
      "   macro avg       0.92      0.94      0.93        54\n",
      "weighted avg       0.93      0.93      0.93        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, tree_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "теперь обучим набор деревьев: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "forest = RandomForestClassifier(n_estimators=3, max_depth=5, verbose=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "используемые параметры модели: \n",
    "- n_estimators : число деревьев в ансамбле (лесе)\n",
    "- max_depth : глубина дерева \n",
    "- verbose : пояснения о процессе обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 3\n",
      "building tree 2 of 3\n",
      "building tree 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, n_estimators=3, verbose=5)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "forest_y_pred = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91        17\n",
      "           1       0.89      0.96      0.92        25\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.93        54\n",
      "   macro avg       0.94      0.92      0.93        54\n",
      "weighted avg       0.93      0.93      0.93        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, forest_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=10, verbose=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "используемые параметры [модели](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier):\n",
    "- loss : The loss function to be optimized. ‘deviance’ refers to deviance (= logistic regression) for classification with probabilistic outputs. For loss ‘exponential’ gradient boosting recovers the AdaBoost algorithm.\n",
    "- n_estimators : The number of boosting stages to perform. Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance.\n",
    "- random_state : Controls the random seed given to each Tree estimator at each boosting iteration. In addition, it controls the random permutation of the features at each split (see Notes for more details). It also controls the random spliting of the training data to obtain a validation set if n_iter_no_change is not None. Pass an int for reproducible output across multiple function calls. See Glossary.\n",
    "- verbose : Enable verbose output. If 1 then it prints progress and performance once in a while (the more trees the lower the frequency). If greater than 1 then it prints progress and performance for every tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.9061            0.78s\n",
      "         2           0.7605            0.63s\n",
      "         3           0.6443            0.64s\n",
      "         4           0.5493            0.59s\n",
      "         5           0.4708            0.57s\n",
      "         6           0.4051            0.55s\n",
      "         7           0.3497            0.52s\n",
      "         8           0.3026            0.51s\n",
      "         9           0.2628            0.49s\n",
      "        10           0.2282            0.51s\n",
      "        11           0.1988            0.51s\n",
      "        12           0.1735            0.51s\n",
      "        13           0.1519            0.51s\n",
      "        14           0.1331            0.52s\n",
      "        15           0.1162            0.52s\n",
      "        16           0.1016            0.52s\n",
      "        17           0.0889            0.52s\n",
      "        18           0.0778            0.52s\n",
      "        19           0.0682            0.51s\n",
      "        20           0.0598            0.51s\n",
      "        21           0.0525            0.51s\n",
      "        22           0.0461            0.51s\n",
      "        23           0.0405            0.50s\n",
      "        24           0.0356            0.49s\n",
      "        25           0.0313            0.47s\n",
      "        26           0.0275            0.46s\n",
      "        27           0.0241            0.45s\n",
      "        28           0.0212            0.44s\n",
      "        29           0.0186            0.43s\n",
      "        30           0.0164            0.42s\n",
      "        31           0.0144            0.41s\n",
      "        32           0.0127            0.40s\n",
      "        33           0.0112            0.40s\n",
      "        34           0.0098            0.39s\n",
      "        35           0.0087            0.39s\n",
      "        36           0.0076            0.38s\n",
      "        37           0.0067            0.38s\n",
      "        38           0.0059            0.37s\n",
      "        39           0.0052            0.37s\n",
      "        40           0.0046            0.37s\n",
      "        41           0.0040            0.36s\n",
      "        42           0.0035            0.36s\n",
      "        43           0.0031            0.35s\n",
      "        44           0.0028            0.35s\n",
      "        45           0.0024            0.34s\n",
      "        46           0.0021            0.34s\n",
      "        47           0.0018            0.33s\n",
      "        48           0.0016            0.33s\n",
      "        49           0.0014            0.32s\n",
      "        50           0.0012            0.32s\n",
      "        51           0.0011            0.31s\n",
      "        52           0.0009            0.30s\n",
      "        53           0.0008            0.30s\n",
      "        54           0.0007            0.29s\n",
      "        55           0.0006            0.28s\n",
      "        56           0.0006            0.27s\n",
      "        57           0.0005            0.27s\n",
      "        58           0.0004            0.26s\n",
      "        59           0.0004            0.25s\n",
      "        60           0.0003            0.24s\n",
      "        61           0.0003            0.24s\n",
      "        62           0.0003            0.23s\n",
      "        63           0.0002            0.22s\n",
      "        64           0.0002            0.22s\n",
      "        65           0.0002            0.21s\n",
      "        66           0.0001            0.20s\n",
      "        67           0.0001            0.20s\n",
      "        68           0.0001            0.19s\n",
      "        69           0.0001            0.18s\n",
      "        70           0.0001            0.18s\n",
      "        71           0.0001            0.17s\n",
      "        72           0.0001            0.16s\n",
      "        73           0.0001            0.16s\n",
      "        74           0.0001            0.15s\n",
      "        75           0.0000            0.15s\n",
      "        76           0.0000            0.14s\n",
      "        77           0.0000            0.13s\n",
      "        78           0.0000            0.13s\n",
      "        79           0.0000            0.12s\n",
      "        80           0.0000            0.12s\n",
      "        81           0.0000            0.11s\n",
      "        82           0.0000            0.10s\n",
      "        83           0.0000            0.10s\n",
      "        84           0.0000            0.09s\n",
      "        85           0.0000            0.09s\n",
      "        86           0.0000            0.08s\n",
      "        87           0.0000            0.07s\n",
      "        88           0.0000            0.07s\n",
      "        89           0.0000            0.06s\n",
      "        90           0.0000            0.06s\n",
      "        91           0.0000            0.05s\n",
      "        92           0.0000            0.05s\n",
      "        93           0.0000            0.04s\n",
      "        94           0.0000            0.03s\n",
      "        95           0.0000            0.03s\n",
      "        96           0.0000            0.02s\n",
      "        97           0.0000            0.02s\n",
      "        98           0.0000            0.01s\n",
      "        99           0.0000            0.01s\n",
      "       100           0.0000            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=10, verbose=5)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_y_pred = gb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91        17\n",
      "           1       0.96      0.92      0.94        25\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.94        54\n",
      "   macro avg       0.95      0.95      0.95        54\n",
      "weighted avg       0.95      0.94      0.94        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, gb_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько деревьев мы обучили? Сколько было бы достаточно для получения текущего качества?\n",
    "(подсказка: посмотрите на loss и n_estimators)\n",
    "\n",
    "**Early stopping** - метод, при котором перестаем обучаться, если ошибка не уменьшается/ уменьшается незначительно. За это отвечают следующие параметры модели:\n",
    "\n",
    "- tol : tolerance for the early stopping, оставим значение дефолтным\n",
    "- n_iter_no_change :  останавливаем ли обучение, если validation score больше не увеличивается<br>\n",
    "(если функция ошибки(train loss) не уменьшается хотя бы на tol в течение n_iter_no_change итераций, то прекращаем обучение)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf_es = GradientBoostingClassifier(n_iter_no_change=5, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.9055            0.91s\n",
      "         2           0.7600            0.88s\n",
      "         3           0.6436            1.00s\n",
      "         4           0.5488            0.90s\n",
      "         5           0.4703            0.82s\n",
      "         6           0.4035            0.83s\n",
      "         7           0.3472            0.82s\n",
      "         8           0.2996            0.79s\n",
      "         9           0.2590            0.76s\n",
      "        10           0.2244            0.75s\n",
      "        11           0.1946            0.74s\n",
      "        12           0.1690            0.73s\n",
      "        13           0.1469            0.70s\n",
      "        14           0.1278            0.68s\n",
      "        15           0.1113            0.65s\n",
      "        16           0.0970            0.63s\n",
      "        17           0.0846            0.61s\n",
      "        18           0.0738            0.60s\n",
      "        19           0.0644            0.58s\n",
      "        20           0.0562            0.57s\n",
      "        21           0.0491            0.56s\n",
      "        22           0.0429            0.54s\n",
      "        23           0.0375            0.53s\n",
      "        24           0.0327            0.52s\n",
      "        25           0.0286            0.51s\n",
      "        26           0.0250            0.50s\n",
      "        27           0.0219            0.48s\n",
      "        28           0.0191            0.47s\n",
      "        29           0.0167            0.46s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(n_iter_no_change=5, verbose=10)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf_es.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_y_pred = gb_clf_es.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91        17\n",
      "           1       0.96      0.92      0.94        25\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.94        54\n",
      "   macro avg       0.95      0.95      0.95        54\n",
      "weighted avg       0.95      0.94      0.94        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, es_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнивая метрики, какой алгоритм оказался лучше?\n",
    "\n",
    "Можно посмотреть коэффициенты важности признаков для разных моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.396020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.387435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.105140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.081013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.018235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "12  0.396020\n",
       "6   0.387435\n",
       "9   0.105140\n",
       "4   0.081013\n",
       "7   0.018235"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "pd.DataFrame(tree_clf.feature_importances_).nlargest(5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.171758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.145654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.138226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.112278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.103266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "12  0.171758\n",
       "5   0.145654\n",
       "10  0.138226\n",
       "6   0.112278\n",
       "9   0.103266"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "pd.DataFrame(forest.feature_importances_).nlargest(5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.300190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.296082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.268266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.063681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.031499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "6   0.300190\n",
       "9   0.296082\n",
       "12  0.268266\n",
       "4   0.063681\n",
       "2   0.031499"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GradientBoostingClassifier\n",
    "pd.DataFrame(gb_clf.feature_importances_).nlargest(5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.309203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.289139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.262669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.072204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.019162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "6   0.309203\n",
       "9   0.289139\n",
       "12  0.262669\n",
       "4   0.072204\n",
       "2   0.019162"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GradientBoostingClassifier + Early stopping\n",
    "pd.DataFrame(gb_clf_es.feature_importances_).nlargest(5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
