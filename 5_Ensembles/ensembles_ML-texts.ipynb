{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теория"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### где сегодня используются ансамбли\n",
    "- Везде, где можно применять классические алгоритмы (ансамбли дают более точные результаты)\n",
    "- Поисковые системы (ранжирование реультатов)\n",
    "- Компьютерное зрение (распознавание объектов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Идея\n",
    "Если взять несколько методов научить их последовательно исправлять ошибки друг друга, качество такой системы будет выше, чем каждого из методов по отдельности.\n",
    "\n",
    "Лучше, если алгоритмы неустойчивы к аномалиям в данных: поэтому для ансамблей берут Регрессию и Деревья Решений.\n",
    "\n",
    "### Как собрать ансамбль?\n",
    "- ансамбль собирают из supervised-алгоритмов, потому что важно знать, в чем/где ошибаются модели\n",
    "- в плане последовательности можно собрать как угодно, но опытным путем нашлись три способа: *стэкинг*, *бэггинг* и *бустинг*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея: на одних и тех же данных обучаем несколько разных алгоритмов (например, классификации). Передаем реультаты финальному, он принимает решение (обычно это регрессия).\n",
    "\n",
    "<img alt=\"\" width=\"900\" height=\"600\" src=\"https://miro.medium.com/max/1892/0*GHYCJIjkkrP5ZgPh.png\">\n",
    "\n",
    "[ссылка на картинку](https://medium.com/@rrfd/boosting-bagging-and-stacking-ensemble-methods-with-sklearn-and-mlens-a455c0c982de)\n",
    "\n",
    "*С добавлением новых моделей в ансамбль, мы не повысим качество предсказаний*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея: несколько раз тренируем один и тот же алгоритм на разных подвыборках из данных. В результате усредняем ответы и определяем финальный. \n",
    "<img alt=\"\" width=\"700\" height=\"400\" src=\"https://miro.medium.com/max/1920/1*DFHUbdz6EyOuMYP4pDnFlw.jpeg\">\n",
    "\n",
    "[ссылка на картинку](https://medium.com/@rrfd/boosting-bagging-and-stacking-ensemble-methods-with-sklearn-and-mlens-a455c0c982de)\n",
    "\n",
    "Самый популярный бэггинг - это [Random Forest](https://ru.wikipedia.org/wiki/Random_forest) (набор решающих деревьев)<br>\n",
    "Бэггинг -- эффективный метод, если у вас небольшой датасет.<br>\n",
    "[Чем бэггинг отличается от кросс-валидации?](https://www.kaggle.com/questions-and-answers/120778)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея: обучаем алгоритмы последовательно, каждый следующий уделяет внимание ошибкам предыдущего. Продолжаем, пока метрики не станут хорошими\n",
    "\n",
    "<img alt=\"Boosting procedure\" src=\"https://pluralsight2.imgix.net/guides/a9a5ff4e-b617-4afe-b27b-d96793defa87_6.jpg\">\n",
    "\n",
    "[ссылка на картинку](https://www.pluralsight.com/guides/ensemble-methods:-bagging-versus-boosting)\n",
    "\n",
    "[статья про популярные типы бустинга](https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### разница между бэггингом и бустингом\n",
    "\n",
    "<img alt=\"Bagging, Boosting\" width=\"700\" height=\"400\" src=\"https://pluralsight2.imgix.net/guides/81232a78-2e99-4ccc-ba8e-8cd873625fdf_2.jpg\">\n",
    "\n",
    "**Когда что использовать?**\n",
    "- Бэггинг, если у данных высокая дисперсия\n",
    "- Бустинг, если данные неравномерно распределены\n",
    "\n",
    "**Bagging VS Boosting**\n",
    "\n",
    "Нет одноначного ответа, что лучше, это зависит от задачи и данных. Если модель хорошо работает на обучающих данных, но плохо на тестовых, то в данных может быть высокая диспрерсия. Если модель плохо работает на обучающих данных, стоит проверить распределение классов/параметров.\n",
    "Предварительно стоит проаналиировать данные, затем попробовать несколько моделей, постепенно изменяя параметры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поработаем с датасетом [спам-сообщений](https://www.kaggle.com/uciml/sms-spam-collection-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.datasets import load_wine\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## подготовим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('spam.csv', encoding = \"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2 Unnamed: 2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "...         ...        ...  \n",
       "5567        NaN        NaN  \n",
       "5568        NaN        NaN  \n",
       "5569        NaN        NaN  \n",
       "5570        NaN        NaN  \n",
       "5571        NaN        NaN  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      spam                                            content\n",
       "0        0  Go until jurong point, crazy.. Available only ...\n",
       "1        0                      Ok lar... Joking wif u oni...\n",
       "2        1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3        0  U dun say so early hor... U c already then say...\n",
       "4        0  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567     1  This is the 2nd time we have tried 2 contact u...\n",
       "5568     0              Will Ì_ b going to esplanade fr home?\n",
       "5569     0  Pity, * was in mood for that. So...any other s...\n",
       "5570     0  The guy did some bitching but I acted like i'd...\n",
       "5571     0                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'], axis =1, inplace=True) # выкинем ненужные колонки\n",
    "\n",
    "data.rename(columns={\"v1\": \"spam\", \"v2\": \"content\"}, inplace=True) # переименуем колонки\n",
    "\n",
    "# изменим значения в первой колонке: 'spam' в 1  и 'ham' в 0\n",
    "data[\"spam\"]=data[\"spam\"].map({'spam':1,'ham':0}) \n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### немножко EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAGaCAYAAAARqASLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de5xc4+HH8c+zu8nmJonEukTIUYSiqLtSCUUxLkU1rlWqLr1QSh2l7VJ0lNCr6q+qFy2q7npUtdqg1C2Kxi1uhwQhkWRz392ZeX5/nJPaRDJ7m5nnnDPf9+u1r2xmds58ZzfZ7zzPOec5xlqLiIjI6jS4DiAiIsmmohARkbJUFCIiUpaKQkREylJRiIhIWSoKEREpS0UhIiJlqSjqiDEmNMYsNcYsMsa8a4z5jTFmmOtcIpJsKor6c5C1dhiwHbADcIHjPCKScCqKOmWtfQv4C7AVgDHmBGPMC8aYhcaY14wxp3T9emPMIcaYp40xC4wxrxpj9otvn2KMWRaPUhbFI5awy+NCY8x5xpjnjTHzjDG/NsYM6nL/gfF25xtjHjHGbL3S8/7eGNPRZdszu9zXbIy5whjzZjxCusYYM7jL/Z4xxnbJVjTGnBTf12CM8ePX8r4x5mZjzKiVHte0Uo7W+POJK+X4XPz1J3W57cT4+znPGPNXY8y4Vf0cVn4uY8yXjTHPGWNGd/ma35T5HvzIGDMj/rlMNcZ8sst9jcaYb8WvcWF8/wbxfVsaY/5mjJkbf+++1eV7+kNjzNvxxw+NMc1dXncpzrHQGPO4MWarVb0uyRYVRZ2Kf2EcAPwnvuk94EBgOHACcJUxZrv4a3cCfgecA4wE9gDCLpv7qrV2WDxSOWgVT3cM8GlgY2A88SjGGPNx4DrgFGA08AvgruW/mJZHBS6Jt73/StvNx9vbFtgEWB/4Tpf7l//7HhE//qEu930N+AwwARgDzAN+torsZRljBgDfA97pctshwLeAw4CW+Hlv7MG2jgTOBj5trX1/pddx2Wq+B08Qvf5RwA3An7oU8VnAUUQ/5+HAicASY8wawN+Be4le+ybA/fFjzgd2ibe5DbATK446345zjASeAVq7e12SfiqK+nOHMWY+8C/gAeBSAGttYK191UYeAO4Dlr87/SJwnbX2b9bakrX2LWvti714zp9aa2dYa+cClxD98gI4GfiFtfYxa23RWvtboJ3oF9Vyg4GOlTdojDHx48+01s611i6MX8uRXb5sIFCy1hZXkelU4Hxr7UxrbTvRL7zPdh1F9NApwGPA9JW2/X1r7QvW2kKca9vVjSpi+wG/Ava31s5c6b6BrOJ7AGCt/b219n1rbcFaOxloBjaL7z4JuMBa+1L8c30mLqADgVnW2snW2mXW2oXW2sfixxwDXGStfc9aOxu4EDhuFU/dADQC76/iPsmY3v6nkPT7jLX27yvfaIzZH/gu0Tv0BmAI8N/47g2Ae/rxnDO6fP4G0btYgHHA8caYr3W5f2CX+wHWBWavYpstccapUWcA0eijscvXjCIaKazKOOB2Y0ypy21FYJ0uf5/TZdtDiEv1f08WvTP/JlGh/nalbf/IGDO565cTjXjeWE2ea4lGaROAl1a6b7WvwxhzNlGRjwEs0chhrfjuDYBXV/Gw1d1OvJ2uGbv+vADGxG80BsWZ9lnNdiRDNKIQ4qmeW4ErgHWstSOJimH5b8kZRNNGfbVBl883BN7ust1LrLUju3wMsdbeGOcaQLQP5ZlVbHMOsBTYsstjl08xLTeeFd/pdzWD6N171+ceFO+7WW6t5fcBN69iG+cAN1trV/7lPwM4ZaVtD7bWPrKaLBCNsiYBlxhjxq503ypfR7w/4pvA54A145xtdP9zmwF8ZDU53iYquuW6/rwgmnoaSTTS84n+3UjGqSgEonfxzUTv3Avx6GLfLvf/CjjBGPOpeCfw+saYzXux/a8YY8bGO4vPB/4Y3/5L4FRjzM4mMtQYk4vfqUO0r2QW8OTKG7TWluLHX2WMWRsgzvXp+PMNgDOAO1aT6RqiX8rj4q9vifct9NQacb5LVrPt84wxW8bbHmGMOaKb7T1krZ0G/Bj4v/hxTcaYU4GV9690zVAg+rk1GWO+QzSiWO5a4HvGmE3j7+/W8U7yPwPrGWO+Hu+8XsMYs3P8mBuBC+Lvx1pE+3x+v/IT2+j6BEU+GL1IhqkohHh+/3Sid83zgKOBu7rc/zjxDm6id6wPsOK7zu7cQLTP4zWiKY+L4+0+CXwJ+Gn8vK8AXwAwxhxDtHN7I2ChMWYR0VFaY4wx18TbPTd+zKPGmAVEO2iXz8//FZgSZ16VH8Wv8T5jzELgUWDn1XztqgwHfmyt/dCUkLX2duAy4KY41zQ+vBN6dfJEv8SPJ5pSOgE4xFq7dBVf+1eiHdLTiaaIlrHiNN+VRD/T+4AFRIU/OP5570N04MEs4GVgz/gxFxMV87NEU49PxbctN2b5UU9EpX9iD1+XpJjRhYukmkx0qOxJq9ov0s3jvgB41trWlW4fC1xsrf1ChSKKSDc0opCkWkz0LnhlBWBujbOI1DWNKKSq+jqiEJHkUFGIiEhZmnoSEZGyVBQiIlKWikJERMpSUYiISFkqChERKUtFISIiZWn1WBGRCpk6deraTU1N1xItZpnUN+IlYFqhUDhp++23f68nD1BRiIhUSFNT07XrrrvuR1taWuY1NDQk8iS1UqlkZs+evcWsWbOuBQ7uyWOS2ngiImm0VUtLy4KklgRAQ0ODbWlpaSO+DHKPHlPFPCIi9aYhySWxXJyxx7//VRQiIlKW9lGIiFSJ5wfbV3J7YT43tSdfd8sttww/++yzNyyVShx77LFzLr300ln9eV6NKEREMqRQKHDmmWdueM8990yfPn36c7feeuuoqVOnDurPNlUUIiIZMmXKlKHjxo1r32KLLToGDRpkDzvssLm33HLLyP5sU0UhIpIhM2bMGLj++ut3LP/72LFjO956662B/dmmikJERMpSUYiIZMgGG2ywwghi5syZK4ww+kJFISKSIRMmTFgchuGgF198ceCyZcvMbbfdNurwww+f359t6vBYEZEq6enhrJU0YMAAJk+e/OZ+++03vlgscvTRR8/ZYYcdlvVnmyoKEZGMmTRpUtukSZPaKrU9TT2JiEhZKgoRESlLRSEiImWpKEREpCwVhYiIlKWiEBGRsnR4rIhItbSOqOgy47S2dXtexhFHHOHdf//9I0aPHl14+eWXn6vE02pEISKSISeeeOKcu+666+VKblNFISKSIfvvv/+ilpaWQiW3qaIQEZGyVBQiIlKWikJERMpSUYiISFk6PFZEpFp6cDhrpR100EEbPfroo2vMmzevaZ111tna9/23zzzzzDn92aaKQkQkQ+6+++7XK71NTT2JiEhZKgoRESlLRSEiUjmlUqlkXIfoTpyx1NOvV1GIiFTOtNmzZ49IclmUSiUze/bsEcC0nj5GO7Mlszw/WANYDxgWfwzt8ufqPh8GNAJL4o/Fq/h8VX/OAWaE+VxnbV6dJFGhUDhp1qxZ186aNWsrkvtGvARMKxQKJ/X0AcZaW8U8ItXj+cEIYDywCbARsAGwYfyxATCixpFKwFtA2OXj9S6fzwjzuYquwSNSCyoKSby4EHYGtgc2AzaNP1pc5uqDIjCTDwrkOWAq8FSYz7U5zCVSlopCEsXzg0ZgK2AXonLYBdgcSOycbwVY4FXgKaLieBx4PMznljhNJRJTUYhTnh+sA+zKB6WwA9F+gnpXAJ4BHgYeAR4O87mZbiNJvVJRSE15fjAM+DRwMDABGOc2Uaq8AdwD3AX8I8znOhznkTqhopCq8/xgXaJiOAT4FNDsNlEmLATuIyqNIMzn3necRzJMRSFV4fnBFkTFcAiwE9nex+BakWh66i7gzjCfq+hlMEVUFFIRnh80ALvxQTls4jZRXXuJuDSAR8J8Tv/JpV9UFNIvnh98BDgZ+AKwjts0sgqvA9cC14X53CzXYSSdVBTSa54fNBHtczgF2AdNK6VBgWiU8X/AfRplSG+oKKTHPD/YEPgS8EWipTEknTTKkF5RUUhZ8b6HA4BTgf1J7vo10nsaZUiPqChklTw/WA84Kf7Y0HEcqb7lo4xf6FBbWZmKQlbg+cFGwHnA8cBAx3Gk9hYCPwEmh/ncXNdhJBlUFAKA5webAt8CjkXLz0tUGD8mKox5rsOIWyqKOuf5webABcCRRNdhEOlqAVFhXKnCqF8qijrl+cE44EKiEYQKQrrTxgeFMd91GKktFUWdiVdrvYDoJDntg5DeagN+BFylwqgfKoo6EV/851zgdKJLfor0RxtwBXBFmM8tcx1GqktFUQc8PzgKuBJY13UWyZzXgbPCfO4O10GkelQUGeb5wcbA1cC+rrNI5t0LnBHmc9NdB5HKU1FkkOcHA4mmmb4FDHIcR+pHB3AV8L0wn1vsOoxUjooiYzw/mAj8nOg60yIuhMBpYT53r+sgUhkqiozw/KCFaOfi511nEYndCHw9zOfecx1E+kdFkXKeHxii9ZjywCjHcURWNhc4O8znfu06iPSdiiLFPD/YDPgV0ZXlRJLs78Dnw3zuHddBpPe0ZHRKeX5wHDAVlYSkw97AM54f7Oc6iPSeRhQp4/nBEOBnRJceFUkbS7Qv7fwwn+t0HUZ6RkWRIp4fbAncDGzhOotIPz0GHBnmc6HrINI9TT2lhOcHXwSeQCUh2bAz8B/PDw53HUS6pxFFwnl+MAy4BjjGdRaRKrkGOFNrRiWXiiLBPD/YhmiqabzrLCJV9iwwKcznXnQdRD5MU08J5fnBacCjqCSkPmwNPOn5wRdcB5EP04giYTw/aAauA452nUXEkR8RrUhbch1EIiqKBPH8YE3gDmAP11lEHLsNODbM55a6DiIqisTw/GBD4C/oqCaR5f4NHBzmc3NcB6l3KooEiHda3wOMcZ1FJGFeBvYP87lXXQepZ9qZ7ZjnB3sDD6KSEFmVTYF/e36wk+sg9UxF4ZDnB8cSjSSGu84ikmAtwD89PzjYdZB6paJwxPOD84DrgQGus4ikwBDgds8PvuI6SD3SPooa8/ygEfgJcJrrLCIpdTlwbpjP6ZdXjagoasjzg8HATYCG0CL9cyNwXJjPFV0HqQcqihqJS+Ju4FOus4hkxO+B43ViXvVpH0UNxGdb34FKQqSSjiVaUFCqTEVRZZ4fDCQ6y3Rf11lEMuhLnh/80HWIrFNRVJHnBwOAPwEHuM4ikmFneH7wfdchskxFUSXx0U03oh3XIrXge37wbdchskpFUQWeHxjgl4Cu3iVSOxd5fnCW6xBZpKKojsuBE1yHEKlDk+NruUgFqSgqLD7j+huuc4jUsZ95fnC86xBZovMoKsjzg1PQ4XoiSVAEjgnzuT+6DpIFKooKiRcsux2N0kSSogPYK8znHnYdJO1UFBXg+cFHgceANVxnEZEVzAZ2DPO5N1wHSTO9++0nzw9GEJ11rZIQSZ4W4G7PD4a5DpJmKop+8PygAfgDMN51FhFZrY8Bf4j/v0of6BvXPxcCOdchRKRbBwOXug6RVtpH0UeeHxwK3AoY11lEpMcmhfncza5DpI2Kog88P9gSeBTQvKdIuiwCdg7zueddB0kTFUUveX4wEngC2MR1FhHpk+lER0ItcB0kLbSPohfinWE3oJIQSbPxwG/jNdmkB1QUvXMxsL/rECLSb58BznMdIi009dRD8ZnXd7rOISIVUwR2C/O5x1wHSToVRQ94fjAaeA5Yx3UWEamoF4GPh/ncMtdBkkxTTz3zM1QSIlm0OTq/olsaUXTD84PPEl3OVESyqQRMDPO5h1wHSSoVRRmeH7QQTTm1uM4iIlX1GrB1mM8tdh0kiTT1VN7VqCRE6sFHgB+4DpFUGlGshucHk4CbXOcQkZqxwL5hPvd310GSRkWxCp4frEM05TTadRYRqakZwFY6a3tFmnpatWtQSYjUow2Aq1yHSBqNKFbi+cExwO9d5xARpw4M87nAdYikUFF04fnBesA0YJTrLCLi1DvAFmE+N991kCTQ1NOKJqOSEBFYDzjfdYik0Igi5vnBTkTXmNCKkiIC0A58NMznXncdxDWNKD5wBSoJEflAM5B3HSIJNKLgf5c1vc11DhFJpE+E+dy/XYdwqe5HFJ4fDAAuc51DRBJrsusArtV9UQCnApu6DiEiibVrvFJD3arrqSfPD0YArwBruc4iIokWApuH+Vy76yAuJH5EYYzZzxjzkjHmFWOMX+HNn4dKQkS65wGnuw7hSqJHFMaYRmA6sA8wE3gCOMpa+3x/t+35wYbAS8Cg/m5LROpCG7BJmM/NcR2k1pI+otgJeMVa+5q1toNoNddDKrTtS1FJiEjPjQC+6zqEC0kvivWJVnNcbmZ8W794frA9cHR/tyMidedUzw82cx2i1pJeFNVyGTq5TkR6r4k6XNoj6UXxFtGyv8uNjW/rM88PdgQ+1Z9tiEhdO9Lzg37PbKRJ0oviCWBTY8xGxpiBwJHAXf3c5rn9jyUidWwAcIbrELWU6KOeAIwxBwA/BBqB66y1l/R1W54fjAdeIPkFKSLJ1gZsEOZzC10HqYUm1wG6Y629B7inQps7G5WEiPTfCOAk6uRqeIkfUVSK5wfrEp1d2ew4iohkwxtE51UUXAeptnp6d306KgkRqZxxwBGuQ9RCXRSF5weDgZNd5xCRzPmG6wC1UBdFARwDjHYdQkQyZ3vPD/Z0HaLa6qUovuY6gIhk1tmuA1Rb5ndme34wEfin6xwiklkW2CrM5/q9WGlS1cOIoq5OjBGRmjPAWa5DVFOmRxSeH4wB3iQ6WU9EpFoWAeuG+dxi10GqIesjiiNRSYhI9Q0DDncdolqyXhRHuQ4gInXjeNcBqiWzU0+eH2wCvOw6h4jUDQt4YT73pusglZblEYUuTCQitWSAY12HqIYsF4WmnUSk1jI5/ZTJovD84OPA5q5ziEjdGe/5wXauQ1RaJosCjSZExJ1JrgNUWuaKwvMDQ3RYrIiIC5lbUTZzRQHszorX2RYRqaWNPD/YyXWISspiUWjaSURc+5zrAJWUqfMoPD9oAt4B1nKdRUTq2ptE51Rk4hds1kYUe6GSEBH3NgS2ch2iUrJWFPu4DiAiEvuU6wCVkrWiyPyVpkQkNTJTFJnZR+H5wUjgfbJXfix44g4WPXMfGBjQ4rHWAV/n3T9eQKljKQClJW0MXG88ax92AYtfepi2h/5Aw+BhtBx2AY2Dh9M57x3mP/g7Wg451/ErEakrC4BRYT5XdB2kv5pcB6igiWSwJAoL57Bg6t2M+eLVNAxoZvYdeRa/8CDrHvOD/33N7NsvZfCmOwOwcOrdrHv8lSyZ/m8WP/8Aw7c/iPkPXc/IT2ZyCRqRJBsO7Ag86jpIf2XpF+tergNUTamILXRgS0VsoZ3GYaM+uKt9CcveeIYhm+4a3WAasMUCtrMd09DIshnTaBy6JgNGre8ovEhdy8T0U5aKIpP7J5rWWIvhOx3KWz8/gZk/PQ7TPITBG32wlMySl//NoHHb0NA8BIARuxzBezedz9JXHmPoFhNoe+SPjPiETlQXcSQTb2AzsY/C84O1gVlEy/xmSnHZImbffikth5xLQ/NQZt+ZZ8hmuzFsy6gX3735uwzbZl+Gbrbbhx67aNr9lJYuonnMZix4/DYaBg1jzb1PpmHAoFq/DJF6tQxYM8znlrkO0h9ZGVHsSQZLAmBZ+DRNI9ahccgITGMTQ8bvSvtbLwBQXNJGxzvTGbLxjh96XKlzGYv+ez9rbJdj/r/+wOjcWTSP3ZLFz02p8SsQqWuDgA+/i0uZrBRFJoZ3q9I0vIWOt1+i1LkMay3L3niGAaOjpayWvPQwgzfZEdM08EOPW/DYbQzf/iBMYxO20BHVqDHYQnuNX4FI3Uv976esFEUm908ANI/ZjCGb7cY7v/k671z3FbCWNbbZD4DFLzzI0I9O+NBjCgvfj0Ya46Md3GtsfxCzfnsWi57+C0O3mFjL+CKSgR3aqd9H4fnBWGCG6xwiIqtRBEaH+Vyb6yB9lYURRWZHEyKSCY2kfD9FFopiZ9cBRES6sbXrAP2RhaLY0nUAEZFupHol2SwUxRauA4iIdCPVRZHqndmeH6wFzHadQ0SkG+3A0LQuEJj2EYWmnUQkDZqBTV2H6CsVhYhIbaR2+klFISJSGyoKR1QUIpIWKgpHVBQikhapLYrUHvUULy3+ruscIiI9VCQ68il1K3OmeUSh8ydEJE0agY+6DtEXaS4KTTuJSNqkcvopzUWhEYWIpM0mrgP0RZqLYpzrACIivbS26wB9keaiWNd1ABGRXlJR1JiKQkTSRkVRK54fGGAd1zlERHpJRVFDawFNrkOIiPSSiqKG1nMdQESkD0Z6fpC6N7lpLYpUtrKI1D0DtLgO0VtpLYo1XQcQEemj1L3RVVGIiNSWiqJGRrkOICLSRyqKGtGIQkTSSvsoakRFISJppRFFjYx0HUBEpI+Guw7QW2ktikbXAURE+kjnUdRIOi/LJyKSwje6KgoRkdrSiKJGVBQiklYqihpRUYhIWqWuKFIXOKaikKrZzLz5+omN977pOodk0wKGvA051zF6RUUhspLpduy4XRqef3dcw3u7uM4imTTLdYDe0tSTyEosDQ37dvxg2/l26DOus0gmlVwH6C0VhcgqtDNw0B7tV3nL7IBXXGeRzFFR1IiKQqpuAcNG7N1xxZCibXjHdRbJlILrAL2lohApY6ZtGXNox4WLrKXNdRbJjMWuA/SWikKkG8/ajTc9ufOs162l3XUWyYQFrgP0VlqLoug6gNSXv5V22PaiwnFPWas3KdJvC10H6K20FsVc1wGk/vy6uP+u1xf3edB1Dkk9jShq5F3XAaQ+fadwwoQHix97wHUOSTWNKGpERSHOfL7T3+Pl0piHXeeQ1NKIokZUFOKQMQd05HecY4c/5TqJpJJGFDWiohCnOmkaOLH9yk2W2IEvuc4iqZO6Q63TWhTvuQ4gsoghw/dqv3JkwTbMdJ1FUiV1J3CmuSh0mKI4N4tR6xzYcWlHyTLPdRZJhRJaFLA2wnyuE/QfU5LhRbvhR47v9Gday1LXWSTx3qW1TUt41JD2U0hiPFTa+mPnFU561lqdDCplpXKaUkUhUiE3Fffa+RfFA3XYrJTzlusAfaGiEKmgfOHoPe4rbj/FdQ5JLBVFjenIJ0mkkzu/MfH50ob/cp1DEklFUWOp/IZLfTio45JdZtk1n3SdQxJH+yhq7HnXAURWp0hj017tkz+6yA7Sv1PpKpUnaKa5KKa5DiBSzhIGDZ3YfmVLp218w3UWSYwXXQfoizQXRQgsch1CpJw5jGzZryNPyZo5rrOIc2/R2pa6BQEhxUUR5nMWjSokBV616487quP896xN3yUwpaJecB2gr1JbFLH/ug4g0hOP2S22OKvztOetJXVn5UrFqCgcUVFIatxe+uSOPywc/qjrHOKMisIRFYWkyo+Kh+9+Z3FXXSGvPqkoHFFRSOqc0fm1Cf8pbaxrb9ef1B4qbaxN92rdnh+8DaznOodIbzRQKj7Y/PUnx5o5O7vOIjXxBq1tnusQfZX2EQVoVCEpVKKhce/2y7deYIfo3299eMx1gP5QUYg4sozmwRPar1y/3Ta97jqLVN3jrgP0h4pCxKF5DB+1T8flA4rWaDXkbNOIwrGnXAcQ6Y837TpjP9vROt9aUnnWrnSrAEx1HaI/slAU04D3XYcQ6Y//2E03O63zjFespdN1lp468c6lrH35Qra6+oOVdL79j2Vs/fNFbHvNIva9fjFvLywBcOvznWx59SI++evFvL8kuu3VuSUm3bLESfYam0ZrW6ovk5v6ooiX8tChhpJ695Z23i5fOOpxa0nFoYhf2HYA9x47ZIXbztmtmWdPG8bTpw7jwPFNXPRAOwA/ebyDJ740lFO2H8AN/41OTr/gn8u4eM/mmud2INXTTpCBoohNcR1ApBJ+UTxotz8WJ6bihLw9xjUxarBZ4bbhzR/8fXEHLP9bg4H2AizphAGN8NAbBdYd2sCmoxtrmNiZR1wH6K8m1wEqZIrrACKV4hdOnjjOvPvAro0vTHCdpS/Ov38Zv3u2kxHNhn8eH404ztu9mb2vX8yYNRr4/aGDOeJPS7jps0O62VJm/N11gP5K/Ql3AJ4fGGA2MNp1FpFKMJRK/xj4jcc2anh3V9dZygnnlzjwhiVM+/KwD933/YfaWVawXLjnoBVu/90zHcxdatllbCNXPNLBmoMMP9p/EEMGmA9tIwOeo7VtK9ch+isTU0/xfooprnOIVIqloeHTHT/Ybp4d9rTrLH11zNYDuPWFFRfLXdJp+c3TnXxlx4F8d0o7v/3MYHbfsJE/PJuaffi99TfXASohE0URu891AJFK6mBA84T2KzdaZge87DpLT738fvF/n9/5YoHN11rxV8zlD3dw+s4DGdBoWNoJxkT7L5Z0pn9mYzUyURRZ2UcB8FfXAUQqbQHDRnyq/YolDzSf+U6TKSVqTbOjbl3ClLDInCWWsVcu5MKJzdzzSoGX5pRoMDBuZAPX5D6Ydnp7YYnH3y7y3YnRkU5f22kgO/5yMSMHGe6YNNjVy6imDiAVByZ0JxP7KJbz/OAFYHPXOUQqbUvz+it/Hnh+izGMcJ1FeuwBWtsmug5RCVmaegK413UAkWp4zm60yRc7zw6tpd11FumxTEw7gYpCJDX+Udpum+8Wjn/KWkqus0iP/Nl1gErJWlE8AKT6VHmRcn5X/PSuvy7u95DrHNKtV2hte8Z1iErJVFGE+dwy4G7XOUSq6aLC5yf8s7jNFNc5pKxbXQeopEwVRez3rgOIVNsJnd+c8FJp7MOuc8hq3eI6QCVlsSjuRavJSuYZk+u4dKc5driW2U+eN2hte9J1iErKXFGE+VwncLPrHCLVVqBpwIT2qzZdYptfdJ1FVpCpaSfIYFHENP0kdWExg9fYs33yqE7bONN1FvmfTE07QUaLIsznHgFec51DpBbeZdTauY5LO0vWzHWdRZgJPOo6RKVlsihiN7gOIFIr0+0GGx3Xed7b1urwcMd+S2tbdpa7iGW5KDT9JHXl4dJWW51b+NJ/raXY/VdLFVjgOtchqiGzRRHmcyBYI2UAAA2RSURBVC8BmTryQKQ7Nxf33Onq4sGpv6JaSk2htS2TU96ZLYrYH1wHEKm1ywtHfvIvxR0zsWppymRyNAHZL4obQcNwqT+ndZ454b8lT0t91E4bGTwsdrlMF0WYz71LhlZwFOmNz3R8b9d37KgnXOeoEzfQ2pbZAwkyXRSxn7sOIOJCkcamvdonb7nQDn7OdZY68CvXAaqpHoribkBnrkpdWkrzkIntV67TYZtC11ky7Ela26a6DlFNmS+KMJ+zwGTXOURceZ8Ra326I99Qsma26ywZ9UPXAaot80URux6Y5TqEiCuv2zEbTur49hxrWeQ6S8a8TR2sLVcXRRHmc+3Aj13nEHHpCbv5R0/v/OqL1lJwnSVDrqa1rdN1iGqri6KI/Rz0bkrq292lT+wwuXBE5tYicmQxdXKwTN0URZjPzQeudZ1DxLWfFg/d/bbi7lNc58iA62htq4uFGOumKGJXgYbdImd1fnnik6XxD7rOkWJF4Mr+bMAYc50x5j1jzLQKZaqauiqKMJ97kzrY8STSE0d0fGf3GaWWx1znSKk/0toW9nMbvwH263+U6quroohd7jqASBJYGhr27rh8mzY75FnXWVKmCFzY341Yax8EUjF1VXdFEeZzTwN/d51DJAnaGThoQvtVG7TbAa+6zpIi19PaNt11iFqqu6KIXeY6gEhSzGeNNffuuHxQ0Rqda9S9TuAi1yFqrS6LIszn/o4WCxT5nxl27fUP67hwgbUscJ0l4a6jte111yFqrS6LIvYNtAS5yP88YzcZf2rn11+1lg7XWRKqHbjYdQgX6rYownzuv2T4QiMiffHX0k4fv7hw7JPWkrnrPlfAL2htm1mpjRljbgT+DWxmjJlpjPlipbZdaXVbFLFvAwtdhxBJkl8VD/jEDcW9dI7FihYD36/kBq21R1lr17PWDrDWjrXWJnap8rouivjCRhX94YtkwfmFkyY8XNxSl1P9wKW0ttXtzv66LorYVcAbrkOIJM0xnd/a47XSeo+4zpEAr1Hnlyqo+6II87llwLmuc4gkjzGf7rhsh/ftGv9xncSxs2lta3cdwiVjrfZZAXh+8Aiwq+scIkmzBovbHm/+yruDTcd411kcuJ/Wtr1dh3Ct7kcUXZwJOtJDZGULGTpir/bJwwu24S3XWWqsAJzhOkQSqChiYT73GHCT6xwiSfQOo9c9uOPiZSXLfNdZaugaWtuecx0iCVQUK/KBpa5DiCTR89bb+MTOb75pLctcZ6mB94DvuA6RFCqKLuJlyPu9KqRIVk0pbbv1twsnPG0tJddZquxrtLbNcx0iKVQUH3YF8LjrECJJ9fviPrv8qnjAv1znqKLbaW3TdWu6UFGsJMznisCJoPVuRFbn4sKxe9xf/HgWT8ibB3zZdYikUVGsQpjPPUcdLiUs0htf7DxnwoulDbI2sjirns/AXh0VxepdBjzlOoRIkh3YccnO79mRT7rOUSH30tr2G9chkkhFsRphPlcAjidaWlhEVqFA04A92ydvvtg2v+A6Sz8tBE5xHSKpVBRlhPncNOBbrnOIJNliBg/bs/3KtTpt45uus/TDmbS2pTl/VakouncVcL/rECJJ9h5rthzQ8f1SyZr3XWfpg5tobUvsEt9JoKLoRpjPWaIpKB1TLVLGy3asd2znebOsZYnrLL3wGppy6paKogfCfO4t9I9JpFuPlLba8pzCKdOsTcVlhjuBo2ht03XCu6Gi6KEwn/sT8BvXOUSS7pbihJ1+WvxMGq5jcQGtbTq5tgdUFL3zZWCq6xAiSTe58LlP/rm48xTXOcr4K3C56xBpoetR9JLnB2OBJ4B1XWcRSbo7B17w0DYNr33SdY6VvAN8nNa2d10HSQsVRR94fvAJ4J/AQNdZRJKsgVLxX82nTx1j5u7kOkusHZhIa9ujroOkiaae+iDM5x5B68GIdKtEQ+On2idvtdAOTsp1HU5VSfSeiqKPwnzuV8BPXOcQSbqlNA+Z0H7luh226XXHUX6oJTr6RkXRP2cB/3AdQiTp5jJi9L4dlzUVrXnPUYS/A2c7eu7UU1H0Q7we1BFEJ+2ISBmhXW+DIzq+O9daFtb4qV8FJtHaloZzOxJJRdFPYT43FzgEWOQ6i0jSPWXHb/7VztOnW0tnjZ5yIXAwrW1za/R8maSiqIB48cDjAB1CJtKNoLTL9pcXJj1ubdX/v3QAh9La9nyVnyfzVBQVEuZzd6CLsYv0yNXFQ3a7pbjHg1V8ihJwHK1tWtCzAlQUFRTmcxcDV7rOIZIG5xROnfB4abNqXU71DF33unJ0wl0VeH7wM3SehUi3DKXSlIFnPT6u4b1dKrjZS2htu6CC26t7GlFUx1cBrW8v0g1LQ8O+HT/Ydr4d+kyFNvlLlUTlqSiqIL6GxcnAH1xnEUm6dgYOmtB+1bhldsCr/dzUHcBplcgkK1JRVEmYz5WILnh0i+ssIknXxrCRe3dcMbhoG97p4ybuQudKVI2KoorCfK4IHE30j1hEyphpW8Yc2nHhImtp6+VD7wA+S2tbRzVyiYqi6sJ8rpPo7O17XWcRSbpn7cabntx51uvW0t7Dh9wOfI7WtlqdwFeXVBQ1EOZzHcBhREuTi0gZfyvtsO1FheOe6sEJebeikqgJFUWNhPncUuAg4F+us4gk3a+L++96fXGfcifk/Qk4kta2Qq0y1TMVRQ2F+dxiYD/gz66ziCTddwonTHiw+LFVnZB3A3C0SqJ2VBQ1FpfFZ4Cfu84iknSf7/T3eKU05pEuN/0QOFYlUVs6M9shzw/OAS4DjOssIkk1gELHv5u/Om0ts+BmWtsuc52nHqkoHPP84HPA74Bm11lEEqqzmY4TXsofqhNYHVFRJIDnB7sBdwKjXWcRSZj5wGFhPqcjBh1SUSSE5wfjgXuAjV1nEUmIEDggzOdecB2k3mlndkKE+dx0YFfgUddZRBLgCWAXlUQyqCgSJMznZgN7EZ1tKlKvbgImhvncu66DSERTTwnk+UEDkAfOcZ1FpIaWAV8P87lfuA4iK1JRJJjnBwcDvwHWdBxFpNqmA58L87lKXZdCKkhTTwkW5nN3AdsBj7vOIlJFNwE7qCSSSyOKFPD8YCDwA+AM11lEKkhTTSmhokgRzw8OBa4FRrnOItJPmmpKEU09pUiYz90ObA3c7zqLSD9oqillNKJIIc8PDHAWcCkw0HEckZ7SVFNKqShSzPODbYmWXP6o6ywi3XgYOCXM555zHUR6T1NPKRbmc08D2wOXALpesCTRPOBk4JMqifTSiCIj4rWifgbs7TqLSOwG4Mwwn3vPdRDpHxVFxnh+MAm4EhjjOovUrVeB08J87m+ug0hlaOopY8J87o/A5kRXAis6jiP1pZPoAIutVBLZohFFhnl+sA1wNfAJ11kk8/5FtLP6eddBpPI0osiw+Dj13YEvAnMcx5FsWr6zeg+VRHZpRFEnPD8YBXwfOAm9QZD+WwT8GLgizOfmuQ4j1aWiqDOeH2wGfBs4Emh0HEfSZynRdOZl8fVTpA6oKOpUfDjtBcDRqDCke+3A/wHfD/O5d1yHkdpSUdQ5zw82JSqMY1BhyId1AtcBl4T53AzXYcQNFYUA4PnBJkSFcSwqDIkOrb4euCjM5153HUbcUlHICjw/2JgPCqPJcRypvSLwR+DCMJ+b7jqMJIOKQlbJ84OPAD7RPoyhjuNI9c0lutbJ1WE+94brMJIsKgopy/ODNYjK4mSiy7JKtjwN/BS4IcznlroOI8mkopAe8/xgO+BLRMUx3HEc6btlwG3ANWE+95DrMJJ8KgrpNc8PhgKTiEpjF8dxpOf+SzS9dL1OkpPeUFFIv3h+8DGiwjgWWNNxHPmw+cCtwC/DfO4x12EknVQUUhGeHwwCDgMOB/YDhrhNVNfeAu4E7gCmhPlcp+M8knIqCqk4zw8GA/sChwIHAqPdJqoLLwC3E5XDk2E+p//YUjEqCqkqzw8agT2AA+KPLdwmygwLPEpUDHfonAepJhWF1JTnBxsSTU3tT3TZ1mFuE6XKbOAR4B7grjCfm+U4j9QJFYU44/nBQGBbYKf4Y0dgM8C4zJUQBeBZ4N/LP8J87jW3kaReqSgkUTw/GAHsQFQay8tjrNNQtfEeXUqBaD/DEreRRCIqCkk8zw/W44PS2AHYGNgQGOgyVx/NBV4DXo3/fA6NFiThVBSSSp4fGGA9YFz84a3icxeH6BaAN4lKoGshvAa8GuZzbQ4yifSLikIyy/ODtYhKY32ineaD448hq/mz6+cDiZa6WNrlY/nfFxCdyLbyx2xgRpjPFWrx+kRqRUUhIiJlNbgOICIiyaaiEBGRslQUIiJSlopCRETKUlGIiEhZKgoRESlLRSEiImWpKEREpCwVhYiIlKWiEBGRslQUIiJSlopCRETKUlGIiEhZKgoRESlLRSEiImWpKEREpCwVhYiIlKWiEBGRslQUIiJSlopCRETKUlGIiEhZKgoRESlLRSEiImWpKEREpCwVhYiIlKWiEBGRslQUIiJSlopCRETKUlGIiEhZKgoRESlLRSEiImWpKEREpCwVhYiIlKWiEBGRslQUIiJSlopCRETKUlGIiEhZKgoRESlLRSEiImWpKEREpCwVhYiIlKWiEBGRslQUIiJSlopCRETK+n8lC6BxH/tArQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = pd.value_counts(data[\"spam\"])\n",
    "\n",
    "classes.plot(kind='pie',figsize=(7,7),autopct='%0.f%%', legend=True, title =\"Распределение классов\") \n",
    "\n",
    "\n",
    "plt.ylabel('')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### векторизуем тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "X = vectorizer.fit_transform(data['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделение на обучающую и тестовую выборку\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, data[\"spam\"], test_size=0.3, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сначала обучим одно решающее дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_y_pred = tree_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      1429\n",
      "           1       0.88      0.85      0.86       243\n",
      "\n",
      "    accuracy                           0.96      1672\n",
      "   macro avg       0.93      0.92      0.92      1672\n",
      "weighted avg       0.96      0.96      0.96      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, tree_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "теперь обучим набор деревьев: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "forest = RandomForestClassifier(n_estimators=500, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "используемые параметры модели: \n",
    "- n_estimators : число деревьев в ансамбле (лесе)\n",
    "- max_depth : глубина дерева \n",
    "- verbose : пояснения о процессе обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   43.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, verbose=1)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    1.1s finished\n"
     ]
    }
   ],
   "source": [
    "forest_y_pred = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1429\n",
      "           1       0.99      0.82      0.90       243\n",
      "\n",
      "    accuracy                           0.97      1672\n",
      "   macro avg       0.98      0.91      0.94      1672\n",
      "weighted avg       0.97      0.97      0.97      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, forest_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_estimators=1000, random_state=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "используемые параметры [модели](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier):\n",
    "- loss : The loss function to be optimized. ‘deviance’ refers to deviance (= logistic regression) for classification with probabilistic outputs. For loss ‘exponential’ gradient boosting recovers the AdaBoost algorithm.\n",
    "- n_estimators : The number of boosting stages to perform. Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance.\n",
    "- random_state : Controls the random seed given to each Tree estimator at each boosting iteration. In addition, it controls the random permutation of the features at each split (see Notes for more details). It also controls the random spliting of the training data to obtain a validation set if n_iter_no_change is not None. Pass an int for reproducible output across multiple function calls. See Glossary.\n",
    "- verbose : Enable verbose output. If 1 then it prints progress and performance once in a while (the more trees the lower the frequency). If greater than 1 then it prints progress and performance for every tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6985            2.74m\n",
      "         2           0.6577            3.69m\n",
      "         3           0.6243            4.34m\n",
      "         4           0.6019            4.17m\n",
      "         5           0.5764            3.94m\n",
      "         6           0.5568            3.60m\n",
      "         7           0.5373            3.57m\n",
      "         8           0.5217            3.41m\n",
      "         9           0.5091            3.41m\n",
      "        10           0.4959            3.28m\n",
      "        20           0.4003            2.42m\n",
      "        30           0.3404            2.14m\n",
      "        40           0.2986            2.33m\n",
      "        50           0.2681            2.19m\n",
      "        60           0.2429            2.02m\n",
      "        70           0.2232            1.95m\n",
      "        80           0.2062            1.83m\n",
      "        90           0.1925            1.77m\n",
      "       100           0.1749            1.67m\n",
      "       200           0.1064            1.22m\n",
      "       300           0.0774           57.38s\n",
      "       400           0.0591           44.96s\n",
      "       500           0.0463           36.20s\n",
      "       600           0.0365           27.67s\n",
      "       700           0.0290           20.06s\n",
      "       800           0.0233           13.01s\n",
      "       900           0.0188            6.39s\n",
      "      1000           0.0153            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(n_estimators=1000, random_state=10, verbose=1)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_y_pred = gb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1429\n",
      "           1       0.98      0.83      0.90       243\n",
      "\n",
      "    accuracy                           0.97      1672\n",
      "   macro avg       0.97      0.91      0.94      1672\n",
      "weighted avg       0.97      0.97      0.97      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, gb_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько деревьев мы обучили? Сколько было бы достаточно для получения текущего качества?\n",
    "(подсказка: посмотрите на loss и n_estimators)\n",
    "\n",
    "**Early stopping** - метод, при котором перестаем обучаться, если ошибка не уменьшается/ уменьшается незначительно. За это отвечают следующие параметры модели:\n",
    "\n",
    "- tol : tolerance for the early stopping, оставим значение дефолтным\n",
    "- n_iter_no_change :  останавливаем ли обучение, если validation score больше не увеличивается<br>\n",
    "(если функция ошибки(train loss) не уменьшается хотя бы на tol в течение n_iter_no_change итераций, то прекращаем обучение)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf_es = GradientBoostingClassifier(n_iter_no_change=5, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.6986            4.42s\n",
      "         2           0.6597            5.27s\n",
      "         3           0.6288            5.63s\n",
      "         4           0.6051            6.50s\n",
      "         5           0.5802            6.04s\n",
      "         6           0.5605            5.60s\n",
      "         7           0.5437            5.23s\n",
      "         8           0.5290            4.93s\n",
      "         9           0.5147            4.69s\n",
      "        10           0.4990            4.58s\n",
      "        11           0.4878            4.56s\n",
      "        12           0.4758            4.51s\n",
      "        13           0.4632            4.43s\n",
      "        14           0.4518            4.35s\n",
      "        15           0.4416            4.30s\n",
      "        16           0.4340            4.26s\n",
      "        17           0.4258            4.15s\n",
      "        18           0.4182            4.03s\n",
      "        19           0.4115            3.93s\n",
      "        20           0.4030            3.82s\n",
      "        21           0.3968            3.75s\n",
      "        22           0.3887            3.67s\n",
      "        23           0.3813            3.60s\n",
      "        24           0.3763            3.51s\n",
      "        25           0.3703            3.42s\n",
      "        26           0.3648            3.36s\n",
      "        27           0.3600            3.49s\n",
      "        28           0.3550            3.49s\n",
      "        29           0.3497            3.43s\n",
      "        30           0.3455            3.36s\n",
      "        31           0.3419            3.29s\n",
      "        32           0.3365            3.24s\n",
      "        33           0.3313            3.19s\n",
      "        34           0.3282            3.12s\n",
      "        35           0.3241            3.06s\n",
      "        36           0.3208            3.00s\n",
      "        37           0.3177            2.95s\n",
      "        38           0.3136            3.01s\n",
      "        39           0.3104            2.97s\n",
      "        40           0.3071            2.92s\n",
      "        41           0.3002            2.89s\n",
      "        42           0.2967            2.87s\n",
      "        43           0.2932            2.81s\n",
      "        44           0.2904            2.74s\n",
      "        45           0.2877            2.69s\n",
      "        46           0.2836            2.65s\n",
      "        47           0.2812            2.60s\n",
      "        48           0.2785            2.54s\n",
      "        49           0.2755            2.49s\n",
      "        50           0.2729            2.44s\n",
      "        51           0.2705            2.38s\n",
      "        52           0.2665            2.32s\n",
      "        53           0.2634            2.26s\n",
      "        54           0.2613            2.20s\n",
      "        55           0.2592            2.14s\n",
      "        56           0.2571            2.09s\n",
      "        57           0.2534            2.03s\n",
      "        58           0.2510            1.97s\n",
      "        59           0.2484            1.92s\n",
      "        60           0.2462            1.86s\n",
      "        61           0.2441            1.81s\n",
      "        62           0.2427            1.76s\n",
      "        63           0.2397            1.71s\n",
      "        64           0.2374            1.68s\n",
      "        65           0.2359            1.63s\n",
      "        66           0.2343            1.59s\n",
      "        67           0.2327            1.56s\n",
      "        68           0.2301            1.52s\n",
      "        69           0.2282            1.48s\n",
      "        70           0.2265            1.45s\n",
      "        71           0.2244            1.40s\n",
      "        72           0.2214            1.35s\n",
      "        73           0.2201            1.31s\n",
      "        74           0.2184            1.27s\n",
      "        75           0.2155            1.22s\n",
      "        76           0.2132            1.17s\n",
      "        77           0.2117            1.12s\n",
      "        78           0.2107            1.08s\n",
      "        79           0.2083            1.03s\n",
      "        80           0.2066            0.98s\n",
      "        81           0.2056            0.93s\n",
      "        82           0.2041            0.88s\n",
      "        83           0.2017            0.84s\n",
      "        84           0.1994            0.79s\n",
      "        85           0.1972            0.77s\n",
      "        86           0.1959            0.76s\n",
      "        87           0.1945            0.71s\n",
      "        88           0.1933            0.66s\n",
      "        89           0.1917            0.60s\n",
      "        90           0.1907            0.55s\n",
      "        91           0.1897            0.49s\n",
      "        92           0.1884            0.44s\n",
      "        93           0.1875            0.38s\n",
      "        94           0.1865            0.33s\n",
      "        95           0.1837            0.27s\n",
      "        96           0.1807            0.22s\n",
      "        97           0.1767            0.16s\n",
      "        98           0.1736            0.11s\n",
      "        99           0.1723            0.05s\n",
      "       100           0.1714            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(n_iter_no_change=5, verbose=10)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf_es.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_y_pred = gb_clf_es.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      1429\n",
      "           1       0.97      0.72      0.83       243\n",
      "\n",
      "    accuracy                           0.96      1672\n",
      "   macro avg       0.96      0.86      0.90      1672\n",
      "weighted avg       0.96      0.96      0.95      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, es_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнивая метрики, какой алгоритм оказался лучше?\n",
    "\n",
    "Можно посмотреть коэффициенты важности признаков для разных моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "df1 = pd.DataFrame(tree_clf.feature_importances_)\n",
    "\n",
    "df1[\"feature\"] = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7701</th>\n",
       "      <td>0.173862</td>\n",
       "      <td>txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.107384</td>\n",
       "      <td>claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>0.102064</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8274</th>\n",
       "      <td>0.059199</td>\n",
       "      <td>www</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6558</th>\n",
       "      <td>0.054019</td>\n",
       "      <td>service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7818</th>\n",
       "      <td>0.050002</td>\n",
       "      <td>urgent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>0.041273</td>\n",
       "      <td>150p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>0.025193</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7901</th>\n",
       "      <td>0.023085</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>0.021113</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  feature\n",
       "7701  0.173862      txt\n",
       "2000  0.107384    claim\n",
       "3265  0.102064     free\n",
       "8274  0.059199      www\n",
       "6558  0.054019  service\n",
       "7818  0.050002   urgent\n",
       "351   0.041273     150p\n",
       "607   0.025193       50\n",
       "7901  0.023085    video\n",
       "722   0.021113      800"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.nlargest(10,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7701</th>\n",
       "      <td>0.030450</td>\n",
       "      <td>txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>0.025201</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4951</th>\n",
       "      <td>0.022337</td>\n",
       "      <td>mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8274</th>\n",
       "      <td>0.021049</td>\n",
       "      <td>www</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.020235</td>\n",
       "      <td>claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>0.018433</td>\n",
       "      <td>150p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7731</th>\n",
       "      <td>0.017160</td>\n",
       "      <td>uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5894</th>\n",
       "      <td>0.016200</td>\n",
       "      <td>prize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>0.012609</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7818</th>\n",
       "      <td>0.012546</td>\n",
       "      <td>urgent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0 feature\n",
       "7701  0.030450     txt\n",
       "3265  0.025201    free\n",
       "4951  0.022337  mobile\n",
       "8274  0.021049     www\n",
       "2000  0.020235   claim\n",
       "351   0.018433    150p\n",
       "7731  0.017160      uk\n",
       "5894  0.016200   prize\n",
       "368   0.012609      18\n",
       "7818  0.012546  urgent"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "df2 = pd.DataFrame(forest.feature_importances_)\n",
    "\n",
    "df2[\"feature\"] = vectorizer.get_feature_names()\n",
    "\n",
    "df2.nlargest(10,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7701</th>\n",
       "      <td>0.129338</td>\n",
       "      <td>txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>0.090023</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.061933</td>\n",
       "      <td>claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8274</th>\n",
       "      <td>0.039860</td>\n",
       "      <td>www</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4951</th>\n",
       "      <td>0.036861</td>\n",
       "      <td>mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>0.033814</td>\n",
       "      <td>150p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7818</th>\n",
       "      <td>0.029880</td>\n",
       "      <td>urgent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6558</th>\n",
       "      <td>0.028642</td>\n",
       "      <td>service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7388</th>\n",
       "      <td>0.025867</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5894</th>\n",
       "      <td>0.023603</td>\n",
       "      <td>prize</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  feature\n",
       "7701  0.129338      txt\n",
       "3265  0.090023     free\n",
       "2000  0.061933    claim\n",
       "8274  0.039860      www\n",
       "4951  0.036861   mobile\n",
       "351   0.033814     150p\n",
       "7818  0.029880   urgent\n",
       "6558  0.028642  service\n",
       "7388  0.025867     text\n",
       "5894  0.023603    prize"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GradientBoostingClassifier\n",
    "df3 = pd.DataFrame(gb_clf.feature_importances_)\n",
    "\n",
    "df3[\"feature\"] = vectorizer.get_feature_names()\n",
    "\n",
    "df3.nlargest(10,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7701</th>\n",
       "      <td>0.142057</td>\n",
       "      <td>txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>0.109697</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.084162</td>\n",
       "      <td>claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8274</th>\n",
       "      <td>0.042564</td>\n",
       "      <td>www</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4951</th>\n",
       "      <td>0.041105</td>\n",
       "      <td>mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>0.040279</td>\n",
       "      <td>150p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7818</th>\n",
       "      <td>0.037436</td>\n",
       "      <td>urgent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7388</th>\n",
       "      <td>0.031944</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>0.029657</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6558</th>\n",
       "      <td>0.025780</td>\n",
       "      <td>service</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  feature\n",
       "7701  0.142057      txt\n",
       "3265  0.109697     free\n",
       "2000  0.084162    claim\n",
       "8274  0.042564      www\n",
       "4951  0.041105   mobile\n",
       "351   0.040279     150p\n",
       "7818  0.037436   urgent\n",
       "7388  0.031944     text\n",
       "607   0.029657       50\n",
       "6558  0.025780  service"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GradientBoostingClassifier + Early stopping\n",
    "\n",
    "df4 = pd.DataFrame(gb_clf_es.feature_importances_)\n",
    "\n",
    "df4[\"feature\"] = vectorizer.get_feature_names()\n",
    "\n",
    "df4.nlargest(10,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'abc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-218-1633634ee3ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"feature\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlargest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'abc' is not defined"
     ]
    }
   ],
   "source": [
    "df5 = pd.DataFrame(abc.feature_importances_)\n",
    "\n",
    "df5[\"feature\"] = vectorizer.get_feature_names()\n",
    "\n",
    "df5.nlargest(10,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
