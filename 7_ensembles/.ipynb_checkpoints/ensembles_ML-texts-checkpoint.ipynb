{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Теория"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Идея\n",
    "Если взять несколько методов научить их последовательно исправлять ошибки друг друга, качество такой системы будет выше, чем каждого из методов по отдельности.\n",
    "\n",
    "Лучше, если алгоритмы неустойчивы к выбросам в данных: поэтому для ансамблей берут Регрессию и Деревья Решений.\n",
    "\n",
    "### Как собрать ансамбль?\n",
    "- ансамбль собирают из supervised-алгоритмов, потому что важно знать, в чем/где ошибаются модели\n",
    "- в плане последовательности можно собрать как угодно, но опытным путем нашлись три эффективных способа: *стэкинг*, *бэггинг* и *бустинг*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### где используются ансамбли\n",
    "- Везде, где можно применять классические алгоритмы (ансамбли дают более точные результаты)\n",
    "- Поисковые системы (ранжирование реультатов)\n",
    "- Компьютерное зрение (распознавание объектов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Из чего состоят ансамбли? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решающее дерево (Decision Tree) - это метод машинного обучения, который использует древовидную структуру для принятия решений. В процессе построения дерева, каждый узел(разветвление) рассматривается как \"вопрос\" с ответом \"да\" или \"нет\", в зависимости от значения выбранного признака. Когда дерево построено, оно может быть использовано для классификации новых объектов. Процесс классификации состоит в том, чтобы проходить по дереву, начиная с корневого узла, и переходить в соответствующий узел на основе ответа \"да\" или \"нет\", пока не будет достигнут *лист*, содержащий ответ.\n",
    "\n",
    "**Как разбиваются данные**\n",
    "Алгоритм построения решающего дерева начинается с корневого узла, который содержит весь набор данных для обучения. Затем алгоритм выбирает наиболее важный признак из набора данных и использует его для разбиения данных на подмножества. Дальше, для каждого полученного подмножества данных, алгоритм рекурсивно повторяет процедуру разбиения, пока не будет достигнут *критерий остановки*.\n",
    "\n",
    "Критерии остановки могут варьироваться в зависимости от задачи, которую необходимо решить. Например, дерево может быть остановлено, когда случается одно из условий:\n",
    "- достигнута определенная глубина дерева,\n",
    "- количество объектов в листе достигает заданного порога,\n",
    "- уменьшение ошибки при дальнейшем разбиении становится незначительным\n",
    "\n",
    "\n",
    "Решающие деревья часто используются для решения задач классификации и регрессии, так как они легко интерпретируемы и позволяют анализировать важность признаков в задаче."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея: на одних и тех же данных обучаем несколько разных алгоритмов (например, классификации). Передаем реультаты финальному, он принимает решение (обычно это регрессия).\n",
    "\n",
    "<img alt=\"\" width=\"900\" height=\"600\" src=\"https://miro.medium.com/max/1892/0*GHYCJIjkkrP5ZgPh.png\">\n",
    "\n",
    "*С добавлением новых моделей в ансамбль, мы не повысим качество предсказаний*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея: несколько раз тренируем один и тот же алгоритм на разных подвыборках из данных. В результате усредняем ответы и определяем финальный. \n",
    "<img alt=\"\" width=\"700\" height=\"400\" src=\"https://miro.medium.com/max/1920/1*DFHUbdz6EyOuMYP4pDnFlw.jpeg\">\n",
    "\n",
    "#[ссылка на картинку](https://medium.com/@rrfd/boosting-bagging-and-stacking-ensemble-methods-with-sklearn-and-mlens-a455c0c982de)\n",
    "\n",
    "Самый популярный бэггинг - это [Random Forest](https://ru.wikipedia.org/wiki/Random_forest) (набор решающих деревьев)<br>\n",
    "Бэггинг -- эффективный метод, если у вас небольшой датасет.<br>\n",
    "[Чем бэггинг отличается от кросс-валидации?](https://www.kaggle.com/questions-and-answers/120778)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея: обучаем алгоритмы последовательно, каждый следующий уделяет внимание ошибкам предыдущего. Продолжаем, пока метрики не станут хорошими\n",
    "\n",
    "<img alt=\"Boosting procedure\" src=\"https://pluralsight2.imgix.net/guides/a9a5ff4e-b617-4afe-b27b-d96793defa87_6.jpg\">\n",
    "\n",
    "[ссылка на картинку](https://www.pluralsight.com/guides/ensemble-methods:-bagging-versus-boosting)\n",
    "\n",
    "[статья про популярные типы бустинга](https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### разница между бэггингом и бустингом\n",
    "\n",
    "<img alt=\"Bagging, Boosting\" width=\"700\" height=\"400\" src=\"https://pluralsight2.imgix.net/guides/81232a78-2e99-4ccc-ba8e-8cd873625fdf_2.jpg\">\n",
    "\n",
    "**Когда что использовать?**\n",
    "- Бэггинг, если у данных высокая дисперсия\n",
    "- Бустинг, если данные неравномерно распределены\n",
    "\n",
    "**Bagging VS Boosting**\n",
    "\n",
    "Нет одноначного ответа, что лучше, это зависит от задачи и данных. Если модель хорошо работает на обучающих данных, но плохо на тестовых, то в данных может быть высокая диспрерсия. Если модель плохо работает на обучающих данных, стоит проверить распределение классов/параметров.\n",
    "Предварительно стоит проаналиировать данные, затем попробовать несколько моделей, постепенно изменяя параметры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Практика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поработаем с уже известным нам датасетом [спам-сообщений](https://www.kaggle.com/uciml/sms-spam-collection-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.datasets import load_wine\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## подготовим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('spam.csv',encoding = \"latin-1\" )\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем немного предобработки данных: удалим ненужные колонки, а нужные удобно переименуем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            content\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# удалим ненужные колонки\n",
    "data.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'], axis =1, inplace=True) \n",
    "\n",
    "# переименуем нужные колонки\n",
    "data.rename(columns={\"v1\": \"label\", \"v2\": \"content\"}, inplace=True) \n",
    "\n",
    "# изменим значения в первой колонке: 'spam' в 1  и 'ham' в 0\n",
    "data[\"label\"]=data[\"label\"].map({'spam':1,'ham':0}) \n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### немножко DA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы помним,  что распределение классов в датасете неравномерное: спама в 3 раза меньше, чем нормальных сообщений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = pd.value_counts(data[\"label\"])\n",
    "\n",
    "classes.plot(kind='pie',figsize=(5,5),autopct='%0.f%%', legend=True, title =\"Распределение классов: 0 = ham; 1 = spam\") \n",
    "\n",
    "\n",
    "plt.ylabel('')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте сбалансируем классы: \n",
    "-  для класса 1 возьмем все сэмплы спама\n",
    "- для класса 0 из подвыборки обычных писем возьмем часть, равную подвыборке спама\n",
    "\n",
    "Для этого нужно выяснить, сколько семплов спама в датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4825\n",
       "1     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# так сбалансируем классы\n",
    "\n",
    "data_balanced = data[data.label == 1].append(data[data.label == 0].sample(n=747))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    747\n",
       "0    747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверяем классы\n",
    "data_balanced.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### векторизуем тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "X = vectorizer.fit_transform(data_balanced['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделение на обучающую и тестовую выборку\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, data_balanced[\"label\"], test_size=0.15, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1269, 4395) (225, 4395)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Решающее дерево"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сегодня мы говорим о способах сделать \"конструктор\" из алгоритмов, и \"кубиком\" в таком конструкторе будет алгоритм *решающего дерева* или *дерева решений*(decision tree).\n",
    "Сначала попробуем обучить одно такое дерево: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_y_pred = tree_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tree_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       106\n",
      "           1       0.92      0.92      0.92       119\n",
      "\n",
      "    accuracy                           0.92       225\n",
      "   macro avg       0.92      0.92      0.92       225\n",
      "weighted avg       0.92      0.92      0.92       225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, tree_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 97   9]\n",
      " [  9 110]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, tree_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем рассматривать эти результаты как baseline и далее экспериментировать с более сложными конструкциями.  Время строить ансамбли!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучим набор деревьев: Random Forest\n",
    "\n",
    "\n",
    "Параметры модели: \n",
    "- n_estimators : число деревьев в ансамбле (лесе)\n",
    "- max_depth : глубина дерева \n",
    "- verbose : пояснения о процессе обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "forest = RandomForestClassifier(n_estimators=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   10.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=500, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=500, verbose=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, verbose=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "forest_y_pred = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(forest_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation:** давайте оценим модель метриками классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.95       106\n",
      "           1       0.98      0.92      0.95       119\n",
      "\n",
      "    accuracy                           0.95       225\n",
      "   macro avg       0.95      0.95      0.95       225\n",
      "weighted avg       0.95      0.95      0.95       225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, forest_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[104,   2],\n",
       "       [ 10, 109]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, forest_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3s/7zr3qj110993h9xz81ybhxxw0000gn/T/ipykernel_58460/847387167.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"forest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "forest.(\"forest\") # how to save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_estimators=500, random_state=10, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3332           32.27s\n",
      "         2           1.2852           33.57s\n",
      "         3           1.2438           29.93s\n",
      "         4           1.2068           27.67s\n",
      "         5           1.1732           26.02s\n",
      "         6           1.1437           24.23s\n",
      "         7           1.1167           22.48s\n",
      "         8           1.0907           21.57s\n",
      "         9           1.0669           21.33s\n",
      "        10           1.0439           20.36s\n",
      "        11           1.0241           20.57s\n",
      "        12           1.0045           20.84s\n",
      "        13           0.9862           20.30s\n",
      "        14           0.9694           20.07s\n",
      "        15           0.9531           19.84s\n",
      "        16           0.9376           19.38s\n",
      "        17           0.9230           18.90s\n",
      "        18           0.9088           18.71s\n",
      "        19           0.8951           19.07s\n",
      "        20           0.8825           18.85s\n",
      "        21           0.8687           18.50s\n",
      "        22           0.8583           18.12s\n",
      "        23           0.8465           17.74s\n",
      "        24           0.8343           17.44s\n",
      "        25           0.8243           17.10s\n",
      "        26           0.8126           17.22s\n",
      "        27           0.8006           17.14s\n",
      "        28           0.7907           16.85s\n",
      "        29           0.7803           16.69s\n",
      "        30           0.7709           16.45s\n",
      "        31           0.7614           16.27s\n",
      "        32           0.7524           16.06s\n",
      "        33           0.7450           15.93s\n",
      "        34           0.7375           15.95s\n",
      "        35           0.7283           16.54s\n",
      "        36           0.7200           16.45s\n",
      "        37           0.7122           16.33s\n",
      "        38           0.7052           16.38s\n",
      "        39           0.6979           16.42s\n",
      "        40           0.6913           16.60s\n",
      "        41           0.6853           16.55s\n",
      "        42           0.6787           16.36s\n",
      "        43           0.6720           16.18s\n",
      "        44           0.6656           16.06s\n",
      "        45           0.6593           16.03s\n",
      "        46           0.6535           16.05s\n",
      "        47           0.6469           15.93s\n",
      "        48           0.6407           15.83s\n",
      "        49           0.6344           15.67s\n",
      "        50           0.6276           15.56s\n",
      "        51           0.6223           15.45s\n",
      "        52           0.6158           15.38s\n",
      "        53           0.6109           15.39s\n",
      "        54           0.6060           15.31s\n",
      "        55           0.6011           15.24s\n",
      "        56           0.5953           15.11s\n",
      "        57           0.5911           15.00s\n",
      "        58           0.5849           14.95s\n",
      "        59           0.5795           14.85s\n",
      "        60           0.5756           14.81s\n",
      "        61           0.5713           14.69s\n",
      "        62           0.5664           14.63s\n",
      "        63           0.5617           14.67s\n",
      "        64           0.5586           14.67s\n",
      "        65           0.5550           14.74s\n",
      "        66           0.5509           14.76s\n",
      "        67           0.5458           14.67s\n",
      "        68           0.5408           14.61s\n",
      "        69           0.5379           14.54s\n",
      "        70           0.5351           14.46s\n",
      "        71           0.5313           14.38s\n",
      "        72           0.5275           14.36s\n",
      "        73           0.5243           14.26s\n",
      "        74           0.5206           14.17s\n",
      "        75           0.5169           14.10s\n",
      "        76           0.5140           14.04s\n",
      "        77           0.5110           14.00s\n",
      "        78           0.5079           13.98s\n",
      "        79           0.5043           13.90s\n",
      "        80           0.5004           13.81s\n",
      "        81           0.4971           13.72s\n",
      "        82           0.4941           13.64s\n",
      "        83           0.4922           13.56s\n",
      "        84           0.4904           13.49s\n",
      "        85           0.4875           13.48s\n",
      "        86           0.4852           13.45s\n",
      "        87           0.4816           13.46s\n",
      "        88           0.4777           13.40s\n",
      "        89           0.4747           13.33s\n",
      "        90           0.4726           13.26s\n",
      "        91           0.4698           13.30s\n",
      "        92           0.4670           13.31s\n",
      "        93           0.4642           13.31s\n",
      "        94           0.4617           13.25s\n",
      "        95           0.4592           13.18s\n",
      "        96           0.4574           13.12s\n",
      "        97           0.4548           13.17s\n",
      "        98           0.4521           14.44s\n",
      "        99           0.4496           14.47s\n",
      "       100           0.4475           14.37s\n",
      "       101           0.4451           14.28s\n",
      "       102           0.4432           14.18s\n",
      "       103           0.4411           14.08s\n",
      "       104           0.4391           13.99s\n",
      "       105           0.4372           13.92s\n",
      "       106           0.4354           13.84s\n",
      "       107           0.4328           13.83s\n",
      "       108           0.4309           13.77s\n",
      "       109           0.4285           13.69s\n",
      "       110           0.4264           13.61s\n",
      "       111           0.4244           13.52s\n",
      "       112           0.4215           13.45s\n",
      "       113           0.4196           13.38s\n",
      "       114           0.4176           13.34s\n",
      "       115           0.4154           13.34s\n",
      "       116           0.4132           13.31s\n",
      "       117           0.4115           13.26s\n",
      "       118           0.4097           13.22s\n",
      "       119           0.4081           13.19s\n",
      "       120           0.4059           13.16s\n",
      "       121           0.4031           13.14s\n",
      "       122           0.4010           13.11s\n",
      "       123           0.3993           13.03s\n",
      "       124           0.3975           12.97s\n",
      "       125           0.3957           12.91s\n",
      "       126           0.3942           12.85s\n",
      "       127           0.3929           12.80s\n",
      "       128           0.3917           12.74s\n",
      "       129           0.3904           12.69s\n",
      "       130           0.3875           12.63s\n",
      "       131           0.3851           12.58s\n",
      "       132           0.3827           12.69s\n",
      "       133           0.3812           12.85s\n",
      "       134           0.3794           12.81s\n",
      "       135           0.3776           12.76s\n",
      "       136           0.3754           12.74s\n",
      "       137           0.3738           12.67s\n",
      "       138           0.3721           12.60s\n",
      "       139           0.3701           12.54s\n",
      "       140           0.3688           12.48s\n",
      "       141           0.3659           12.43s\n",
      "       142           0.3648           12.43s\n",
      "       143           0.3633           12.42s\n",
      "       144           0.3618           12.36s\n",
      "       145           0.3608           12.31s\n",
      "       146           0.3599           12.26s\n",
      "       147           0.3579           12.20s\n",
      "       148           0.3565           12.19s\n",
      "       149           0.3552           12.25s\n",
      "       150           0.3531           12.63s\n",
      "       151           0.3520           12.61s\n",
      "       152           0.3502           12.96s\n",
      "       153           0.3486           13.12s\n",
      "       154           0.3460           13.21s\n",
      "       155           0.3451           13.24s\n",
      "       156           0.3435           13.20s\n",
      "       157           0.3422           13.16s\n",
      "       158           0.3411           13.10s\n",
      "       159           0.3399           13.04s\n",
      "       160           0.3389           12.96s\n",
      "       161           0.3374           12.91s\n",
      "       162           0.3356           12.85s\n",
      "       163           0.3337           12.79s\n",
      "       164           0.3325           12.74s\n",
      "       165           0.3318           12.69s\n",
      "       166           0.3310           12.63s\n",
      "       167           0.3300           12.56s\n",
      "       168           0.3292           12.50s\n",
      "       169           0.3276           12.52s\n",
      "       170           0.3262           12.50s\n",
      "       171           0.3249           12.44s\n",
      "       172           0.3228           12.39s\n",
      "       173           0.3211           12.34s\n",
      "       174           0.3204           12.27s\n",
      "       175           0.3181           12.23s\n",
      "       176           0.3174           12.23s\n",
      "       177           0.3166           12.19s\n",
      "       178           0.3153           12.19s\n",
      "       179           0.3141           12.14s\n",
      "       180           0.3126           12.14s\n",
      "       181           0.3108           12.21s\n",
      "       182           0.3095           12.19s\n",
      "       183           0.3084           12.15s\n",
      "       184           0.3075           12.09s\n",
      "       185           0.3069           12.05s\n",
      "       186           0.3062           11.99s\n",
      "       187           0.3046           11.93s\n",
      "       188           0.3025           11.89s\n",
      "       189           0.3017           11.83s\n",
      "       190           0.3002           11.77s\n",
      "       191           0.2989           11.72s\n",
      "       192           0.2972           11.67s\n",
      "       193           0.2966           11.61s\n",
      "       194           0.2958           11.54s\n",
      "       195           0.2938           11.48s\n",
      "       196           0.2925           11.43s\n",
      "       197           0.2919           11.37s\n",
      "       198           0.2906           11.32s\n",
      "       199           0.2897           11.27s\n",
      "       200           0.2887           11.25s\n",
      "       201           0.2878           11.20s\n",
      "       202           0.2863           11.17s\n",
      "       203           0.2858           11.14s\n",
      "       204           0.2853           11.09s\n",
      "       205           0.2844           11.03s\n",
      "       206           0.2832           10.97s\n",
      "       207           0.2816           10.91s\n",
      "       208           0.2806           10.85s\n",
      "       209           0.2797           10.80s\n",
      "       210           0.2790           10.75s\n",
      "       211           0.2779           10.71s\n",
      "       212           0.2766           10.70s\n",
      "       213           0.2761           10.65s\n",
      "       214           0.2748           10.60s\n",
      "       215           0.2736           10.54s\n",
      "       216           0.2729           10.49s\n",
      "       217           0.2722           10.44s\n",
      "       218           0.2708           10.41s\n",
      "       219           0.2699           10.38s\n",
      "       220           0.2694           10.33s\n",
      "       221           0.2685           10.28s\n",
      "       222           0.2675           10.22s\n",
      "       223           0.2666           10.17s\n",
      "       224           0.2657           10.14s\n",
      "       225           0.2647           10.10s\n",
      "       226           0.2642           10.07s\n",
      "       227           0.2638           10.01s\n",
      "       228           0.2621            9.96s\n",
      "       229           0.2611            9.91s\n",
      "       230           0.2600            9.87s\n",
      "       231           0.2592            9.83s\n",
      "       232           0.2581            9.85s\n",
      "       233           0.2575            9.79s\n",
      "       234           0.2564            9.74s\n",
      "       235           0.2551            9.69s\n",
      "       236           0.2541            9.65s\n",
      "       237           0.2534            9.61s\n",
      "       238           0.2525            9.58s\n",
      "       239           0.2520            9.54s\n",
      "       240           0.2510            9.49s\n",
      "       241           0.2505            9.44s\n",
      "       242           0.2495            9.40s\n",
      "       243           0.2491            9.35s\n",
      "       244           0.2487            9.30s\n",
      "       245           0.2483            9.25s\n",
      "       246           0.2472            9.20s\n",
      "       247           0.2458            9.17s\n",
      "       248           0.2453            9.12s\n",
      "       249           0.2445            9.07s\n",
      "       250           0.2433            9.02s\n",
      "       251           0.2423            8.99s\n",
      "       252           0.2414            8.96s\n",
      "       253           0.2408            8.91s\n",
      "       254           0.2394            8.86s\n",
      "       255           0.2390            8.85s\n",
      "       256           0.2385            8.81s\n",
      "       257           0.2378            8.78s\n",
      "       258           0.2372            8.75s\n",
      "       259           0.2365            8.71s\n",
      "       260           0.2353            8.67s\n",
      "       261           0.2344            8.63s\n",
      "       262           0.2328            8.62s\n",
      "       263           0.2324            8.58s\n",
      "       264           0.2319            8.53s\n",
      "       265           0.2316            8.48s\n",
      "       266           0.2312            8.43s\n",
      "       267           0.2301            8.38s\n",
      "       268           0.2290            8.35s\n",
      "       269           0.2286            8.32s\n",
      "       270           0.2279            8.29s\n",
      "       271           0.2275            8.24s\n",
      "       272           0.2271            8.19s\n",
      "       273           0.2267            8.14s\n",
      "       274           0.2256            8.09s\n",
      "       275           0.2249            8.05s\n",
      "       276           0.2245            8.01s\n",
      "       277           0.2237            7.97s\n",
      "       278           0.2229            7.93s\n",
      "       279           0.2226            7.89s\n",
      "       280           0.2215            7.84s\n",
      "       281           0.2208            7.79s\n",
      "       282           0.2198            7.75s\n",
      "       283           0.2193            7.70s\n",
      "       284           0.2188            7.66s\n",
      "       285           0.2185            7.65s\n",
      "       286           0.2181            7.61s\n",
      "       287           0.2176            7.56s\n",
      "       288           0.2168            7.52s\n",
      "       289           0.2162            7.47s\n",
      "       290           0.2147            7.44s\n",
      "       291           0.2135            7.42s\n",
      "       292           0.2127            7.58s\n",
      "       293           0.2123            7.60s\n",
      "       294           0.2117            7.57s\n",
      "       295           0.2111            7.54s\n",
      "       296           0.2106            7.50s\n",
      "       297           0.2097            7.46s\n",
      "       298           0.2091            7.42s\n",
      "       299           0.2083            7.37s\n",
      "       300           0.2080            7.32s\n",
      "       301           0.2068            7.28s\n",
      "       302           0.2062            7.24s\n",
      "       303           0.2051            7.20s\n",
      "       304           0.2046            7.16s\n",
      "       305           0.2038            7.12s\n",
      "       306           0.2034            7.08s\n",
      "       307           0.2031            7.03s\n",
      "       308           0.2028            6.99s\n",
      "       309           0.2024            6.96s\n",
      "       310           0.2017            6.93s\n",
      "       311           0.2012            6.91s\n",
      "       312           0.2006            6.89s\n",
      "       313           0.1999            6.90s\n",
      "       314           0.1993            6.86s\n",
      "       315           0.1988            6.82s\n",
      "       316           0.1982            6.78s\n",
      "       317           0.1969            6.74s\n",
      "       318           0.1966            6.70s\n",
      "       319           0.1961            6.66s\n",
      "       320           0.1956            6.63s\n",
      "       321           0.1948            6.60s\n",
      "       322           0.1943            6.57s\n",
      "       323           0.1939            6.54s\n",
      "       324           0.1933            6.58s\n",
      "       325           0.1924            6.57s\n",
      "       326           0.1916            6.53s\n",
      "       327           0.1912            6.50s\n",
      "       328           0.1910            6.48s\n",
      "       329           0.1906            6.46s\n",
      "       330           0.1900            6.42s\n",
      "       331           0.1890            6.39s\n",
      "       332           0.1887            6.41s\n",
      "       333           0.1883            6.42s\n",
      "       334           0.1874            6.43s\n",
      "       335           0.1871            6.40s\n",
      "       336           0.1867            6.37s\n",
      "       337           0.1859            6.33s\n",
      "       338           0.1856            6.29s\n",
      "       339           0.1851            6.25s\n",
      "       340           0.1844            6.21s\n",
      "       341           0.1841            6.20s\n",
      "       342           0.1835            6.17s\n",
      "       343           0.1828            6.14s\n",
      "       344           0.1826            6.15s\n",
      "       345           0.1820            6.18s\n",
      "       346           0.1815            6.16s\n",
      "       347           0.1804            6.14s\n",
      "       348           0.1798            6.17s\n",
      "       349           0.1790            6.14s\n",
      "       350           0.1786            6.11s\n",
      "       351           0.1781            6.12s\n",
      "       352           0.1779            6.09s\n",
      "       353           0.1776            6.08s\n",
      "       354           0.1774            6.07s\n",
      "       355           0.1767            6.07s\n",
      "       356           0.1763            6.11s\n",
      "       357           0.1756            6.07s\n",
      "       358           0.1753            6.05s\n",
      "       359           0.1746            6.05s\n",
      "       360           0.1739            6.03s\n",
      "       361           0.1736            6.01s\n",
      "       362           0.1729            6.00s\n",
      "       363           0.1721            6.00s\n",
      "       364           0.1716            5.97s\n",
      "       365           0.1710            5.93s\n",
      "       366           0.1707            5.89s\n",
      "       367           0.1703            5.90s\n",
      "       368           0.1700            5.86s\n",
      "       369           0.1696            5.83s\n",
      "       370           0.1693            5.80s\n",
      "       371           0.1687            5.75s\n",
      "       372           0.1683            5.71s\n",
      "       373           0.1676            5.73s\n",
      "       374           0.1672            5.70s\n",
      "       375           0.1667            5.68s\n",
      "       376           0.1661            5.64s\n",
      "       377           0.1657            5.59s\n",
      "       378           0.1654            5.55s\n",
      "       379           0.1647            5.50s\n",
      "       380           0.1643            5.49s\n",
      "       381           0.1640            5.45s\n",
      "       382           0.1636            5.42s\n",
      "       383           0.1631            5.38s\n",
      "       384           0.1621            5.35s\n",
      "       385           0.1616            5.31s\n",
      "       386           0.1613            5.30s\n",
      "       387           0.1607            5.29s\n",
      "       388           0.1601            5.24s\n",
      "       389           0.1597            5.20s\n",
      "       390           0.1593            5.16s\n",
      "       391           0.1588            5.13s\n",
      "       392           0.1586            5.09s\n",
      "       393           0.1579            5.04s\n",
      "       394           0.1576            5.00s\n",
      "       395           0.1574            4.98s\n",
      "       396           0.1569            4.94s\n",
      "       397           0.1565            4.90s\n",
      "       398           0.1560            4.85s\n",
      "       399           0.1554            4.80s\n",
      "       400           0.1552            4.75s\n",
      "       401           0.1546            4.70s\n",
      "       402           0.1541            4.66s\n",
      "       403           0.1539            4.61s\n",
      "       404           0.1537            4.56s\n",
      "       405           0.1533            4.51s\n",
      "       406           0.1527            4.46s\n",
      "       407           0.1521            4.41s\n",
      "       408           0.1517            4.36s\n",
      "       409           0.1510            4.31s\n",
      "       410           0.1504            4.26s\n",
      "       411           0.1500            4.21s\n",
      "       412           0.1498            4.16s\n",
      "       413           0.1496            4.11s\n",
      "       414           0.1491            4.06s\n",
      "       415           0.1489            4.01s\n",
      "       416           0.1485            3.96s\n",
      "       417           0.1481            3.90s\n",
      "       418           0.1475            3.85s\n",
      "       419           0.1469            3.81s\n",
      "       420           0.1468            3.77s\n",
      "       421           0.1463            3.73s\n",
      "       422           0.1460            3.68s\n",
      "       423           0.1456            3.63s\n",
      "       424           0.1451            3.59s\n",
      "       425           0.1448            3.55s\n",
      "       426           0.1445            3.51s\n",
      "       427           0.1442            3.47s\n",
      "       428           0.1438            3.42s\n",
      "       429           0.1437            3.38s\n",
      "       430           0.1430            3.34s\n",
      "       431           0.1425            3.29s\n",
      "       432           0.1419            3.25s\n",
      "       433           0.1417            3.20s\n",
      "       434           0.1412            3.16s\n",
      "       435           0.1409            3.11s\n",
      "       436           0.1407            3.06s\n",
      "       437           0.1405            3.01s\n",
      "       438           0.1400            2.96s\n",
      "       439           0.1397            2.91s\n",
      "       440           0.1394            2.86s\n",
      "       441           0.1388            2.81s\n",
      "       442           0.1386            2.76s\n",
      "       443           0.1384            2.72s\n",
      "       444           0.1379            2.67s\n",
      "       445           0.1375            2.62s\n",
      "       446           0.1371            2.58s\n",
      "       447           0.1367            2.53s\n",
      "       448           0.1363            2.48s\n",
      "       449           0.1360            2.44s\n",
      "       450           0.1355            2.39s\n",
      "       451           0.1350            2.34s\n",
      "       452           0.1347            2.29s\n",
      "       453           0.1346            2.25s\n",
      "       454           0.1342            2.20s\n",
      "       455           0.1339            2.16s\n",
      "       456           0.1335            2.11s\n",
      "       457           0.1333            2.06s\n",
      "       458           0.1332            2.01s\n",
      "       459           0.1330            1.96s\n",
      "       460           0.1326            1.92s\n",
      "       461           0.1321            1.87s\n",
      "       462           0.1319            1.82s\n",
      "       463           0.1315            1.77s\n",
      "       464           0.1312            1.72s\n",
      "       465           0.1310            1.68s\n",
      "       466           0.1307            1.63s\n",
      "       467           0.1303            1.58s\n",
      "       468           0.1297            1.53s\n",
      "       469           0.1293            1.48s\n",
      "       470           0.1291            1.43s\n",
      "       471           0.1289            1.39s\n",
      "       472           0.1282            1.34s\n",
      "       473           0.1278            1.29s\n",
      "       474           0.1276            1.24s\n",
      "       475           0.1274            1.20s\n",
      "       476           0.1271            1.15s\n",
      "       477           0.1268            1.10s\n",
      "       478           0.1265            1.05s\n",
      "       479           0.1261            1.00s\n",
      "       480           0.1258            0.96s\n",
      "       481           0.1256            0.91s\n",
      "       482           0.1251            0.86s\n",
      "       483           0.1248            0.81s\n",
      "       484           0.1246            0.77s\n",
      "       485           0.1242            0.72s\n",
      "       486           0.1236            0.67s\n",
      "       487           0.1233            0.62s\n",
      "       488           0.1231            0.58s\n",
      "       489           0.1229            0.53s\n",
      "       490           0.1226            0.48s\n",
      "       491           0.1224            0.43s\n",
      "       492           0.1221            0.39s\n",
      "       493           0.1215            0.34s\n",
      "       494           0.1211            0.29s\n",
      "       495           0.1208            0.24s\n",
      "       496           0.1202            0.19s\n",
      "       497           0.1200            0.15s\n",
      "       498           0.1198            0.10s\n",
      "       499           0.1194            0.05s\n",
      "       500           0.1190            0.00s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(n_estimators=500, random_state=10, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(n_estimators=500, random_state=10, verbose=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(n_estimators=500, random_state=10, verbose=10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_y_pred = gb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94       106\n",
      "           1       0.99      0.89      0.94       119\n",
      "\n",
      "    accuracy                           0.94       225\n",
      "   macro avg       0.94      0.94      0.94       225\n",
      "weighted avg       0.94      0.94      0.94       225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, gb_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[105   1]\n",
      " [ 13 106]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, gb_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balanced[\"len\"] = data_balanced.content.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_balanced.len.plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3s/7zr3qj110993h9xz81ybhxxw0000gn/T/ipykernel_58460/1162642827.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswarmplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_balanced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/seaborn/_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mswarmplot\u001b[0;34m(x, y, hue, data, order, hue_order, dodge, orient, color, palette, size, edgecolor, linewidth, ax, **kwargs)\u001b[0m\n\u001b[1;32m   3017\u001b[0m                        linewidth=linewidth))\n\u001b[1;32m   3018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3019\u001b[0;31m     \u001b[0mplotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3020\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, ax, kws)\u001b[0m\n\u001b[1;32m   1418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m         \u001b[0;34m\"\"\"Make the full plot.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_swarmplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_legend_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mdraw_swarmplot\u001b[0;34m(self, ax, kws)\u001b[0m\n\u001b[1;32m   1414\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswarm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswarms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mswarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_offsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1416\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswarm_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswarm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mswarm_points\u001b[0;34m(self, ax, points, center, width, s, **kws)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m         \u001b[0;31m# Do the beeswarm in point coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1318\u001b[0;31m         \u001b[0mnew_xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeeswarm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_xy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0;31m# Transform the point coordinates back to data coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mbeeswarm\u001b[0;34m(self, orig_xy, d)\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             \u001b[0;31m# Find the first candidate that does not overlap any neighbours\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m             new_xy_i = self.first_non_overlapping_candidate(candidates,\n\u001b[0m\u001b[1;32m   1271\u001b[0m                                                             neighbors, d)\n\u001b[1;32m   1272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mfirst_non_overlapping_candidate\u001b[0;34m(self, candidates, neighbors, d)\u001b[0m\n\u001b[1;32m   1227\u001b[0m             \u001b[0mdy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneighbors_y\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0msq_distances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m             \u001b[0;31m# good candidate does not overlap any of neighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.swarmplot(data=data_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько деревьев мы обучили? Сколько было бы достаточно для получения текущего качества?\n",
    "(подсказка: посмотрите на loss и n_estimators)\n",
    "\n",
    "**Early stopping** - метод, при котором перестаем обучаться, если ошибка не уменьшается/ уменьшается незначительно. За это отвечают следующие параметры модели:\n",
    "\n",
    "- tol : tolerance for the early stopping, оставим значение дефолтным\n",
    "- n_iter_no_change :  останавливаем ли обучение, если validation score больше не увеличивается<br>\n",
    "(если функция ошибки(train loss) не уменьшается хотя бы на tol в течение n_iter_no_change итераций, то прекращаем обучение)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf_es = GradientBoostingClassifier(n_iter_no_change=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3335            4.22s\n",
      "         2           1.2889           10.61s\n",
      "         3           1.2469            9.00s\n",
      "         4           1.2115            7.74s\n",
      "         5           1.1790            6.52s\n",
      "         6           1.1499            5.71s\n",
      "         7           1.1231            5.12s\n",
      "         8           1.0978            4.70s\n",
      "         9           1.0745            4.40s\n",
      "        10           1.0521            4.30s\n",
      "        20           0.8883            3.48s\n",
      "        30           0.7770            2.65s\n",
      "        40           0.6957            2.40s\n",
      "        50           0.6339            1.87s\n",
      "        60           0.5808            1.52s\n",
      "        70           0.5426            1.21s\n",
      "        80           0.5074            0.81s\n",
      "        90           0.4784            0.39s\n",
      "       100           0.4518            0.00s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(n_iter_no_change=20, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(n_iter_no_change=20, verbose=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(n_iter_no_change=20, verbose=1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf_es.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_y_pred = gb_clf_es.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90       106\n",
      "           1       0.96      0.84      0.90       119\n",
      "\n",
      "    accuracy                           0.90       225\n",
      "   macro avg       0.90      0.90      0.90       225\n",
      "weighted avg       0.91      0.90      0.90       225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, es_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102   4]\n",
      " [ 19 100]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, es_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнивая метрики, какой алгоритм оказался лучше?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дополнительно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте провести больше экспериментов: измените количество деревьев в ансамбле (n_estimators) и другие параметы в моделях. Как изменения отразятся на метриках качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
