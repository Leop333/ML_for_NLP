{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом дз необходимо обучить модели для классификации. Классификация бинарная, сегодня попробуем отличать настоящие новости от фейковых\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте обучить разные модели для классификации на данных\n",
    "1. Naive Bayes\n",
    "2. SVM \n",
    "3. Decision Trees\n",
    "4. Random Forest\n",
    "5. Boosting\n",
    "\n",
    "для каждого посмотрите на метрики с помощью функции [classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html). Какая/какие модель/ли справляются с задачей наиболее эффективно?\n",
    "\n",
    "PS: Данные уже предобработаны\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ячейка импортов\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, metrics, svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"news_fake-n-true.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим новый датафрейм изз старого\n",
    "\n",
    "data_clean = data.drop(['Unnamed: 0','title','subject','date'], axis=1)\n",
    "\n",
    "display(data_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "давайте посчитаем распределение спама/не спама"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes =pd.value_counts(data[\"label\"])\n",
    "\n",
    "classes.plot(kind = 'pie',  autopct='%0.f%%') \n",
    "# про string formatting https://realpython.com/python-string-formatting/\n",
    "\n",
    "plt.title(\"Classes distribution\")\n",
    "\n",
    "plt.ylabel('')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# векторизуем тексты\n",
    "f = feature_extraction.text.TfidfVectorizer(stop_words = 'english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### идем дальше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = f.fit_transform(data[\"text\"])\n",
    "# print(f.get_feature_names()) # посмотрим на признаки\n",
    "\n",
    "display(X.shape)\n",
    "display(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "метод ```.fit_transform()``` выучивает обучающие данные и возвращает матрицу формата \"документ-термин\" для всего датасета\n",
    "\n",
    "Сейчас у нас 121690 признаков (по числу уникальных слов в корпусе). Новый признак  j  в ряду i  равен 1 если слово j  появляется в тексте i . В ином случае значение признака = 0\n",
    "\n",
    "**давайте попробуем предсказать:** окажется ли текст настоящей новостью или фейковой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на обучающую и тестовую выборку [этой функцией](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "\n",
    "Создадим новые переменные:\n",
    "- X_train - кусочек матрицы \"документ/термин\", который мы \"отдадим\" алгоритму для обучения\n",
    "- X_test - кусочек матрицы \"документ/термин\", на котором будем проверять, как алгоритм сработал \n",
    "- y_train - кусочек датафрейма с текстами, который мы отдадим для обучения\n",
    "- y_test -  кусочек датафрейма с текстами, на котором будем проверять, как алгоритм сработал "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# новые переменные\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, data['label'], \n",
    "                                                                    test_size=0.2,\n",
    "                                                                    random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выбор моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "алгоритмов наивного байеса несколько, мы возьмем [Multinomial NB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes = naive_bayes.MultinomialNB(alpha=0.000010) # используем лучшую модель\n",
    "bayes.fit(X_train, y_train) # тренируем алгоритм на данных\n",
    "\n",
    "bayes.predict(X_test) # метод для предсказания\n",
    "\n",
    "# сделаем датафрейм с колонками для настоящего класса и для предсказанного\n",
    "\n",
    "new_df = pd.DataFrame(data = y_test)\n",
    "new_df[\"predicted\"]=bayes.predict(X_test) # добавляем новую колонку с предсказаниями\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "давайте построим матрицу ошибок ([как работает матрица ошибок](https://en.wikipedia.org/wiki/Confusion_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_confusion_test = metrics.confusion_matrix(y_test, bayes.predict(X_test))\n",
    "\n",
    "\n",
    "pd.DataFrame(data = m_confusion_test, columns = ['Predicted true', 'Predicted fake'],\n",
    "            index = ['Actual true', 'Actual fake'])\n",
    "\n",
    "# m_confusion_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, bayes.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "svc.predict(X_test) # метод для предсказания\n",
    "\n",
    "# сделаем датафрейм с колонками для настоящего класса и для предсказанного\n",
    "\n",
    "new_df = pd.DataFrame(data = y_test)\n",
    "new_df[\"predicted\"]=svc.predict(X_test) # добавляем новую колонку с предсказаниями\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "построим матрицу ошибок для SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_confusion_test = metrics.confusion_matrix(y_test, svc.predict(X_test))\n",
    "\n",
    "pd.DataFrame(data = m_confusion_test, columns = ['Predicted true', 'Predicted fake'],\n",
    "            index = ['Actual true', 'Actual fake'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сначала обучим одно решающее дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_y_pred = tree_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, tree_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "теперь обучим набор деревьев: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "forest = RandomForestClassifier(n_estimators=500, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "используемые параметры модели: \n",
    "- n_estimators : число деревьев в ансамбле (лесе)\n",
    "- max_depth : глубина дерева \n",
    "- verbose : пояснения о процессе обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_y_pred = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, forest_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_estimators=1000, random_state=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "используемые параметры [модели](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier):\n",
    "- loss : The loss function to be optimized. ‘deviance’ refers to deviance (= logistic regression) for classification with probabilistic outputs. For loss ‘exponential’ gradient boosting recovers the AdaBoost algorithm.\n",
    "- n_estimators : The number of boosting stages to perform. Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance.\n",
    "- random_state : Controls the random seed given to each Tree estimator at each boosting iteration. In addition, it controls the random permutation of the features at each split (see Notes for more details). It also controls the random spliting of the training data to obtain a validation set if n_iter_no_change is not None. Pass an int for reproducible output across multiple function calls. See Glossary.\n",
    "- verbose : Enable verbose output. If 1 then it prints progress and performance once in a while (the more trees the lower the frequency). If greater than 1 then it prints progress and performance for every tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_y_pred = gb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, gb_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько деревьев мы обучили? Сколько было бы достаточно для получения текущего качества?\n",
    "(подсказка: посмотрите на loss и n_estimators)\n",
    "\n",
    "**Early stopping** - метод, при котором перестаем обучаться, если ошибка не уменьшается/ уменьшается незначительно. За это отвечают следующие параметры модели:\n",
    "\n",
    "- tol : tolerance for the early stopping, оставим значение дефолтным\n",
    "- n_iter_no_change :  останавливаем ли обучение, если validation score больше не увеличивается<br>\n",
    "(если функция ошибки(train loss) не уменьшается хотя бы на tol в течение n_iter_no_change итераций, то прекращаем обучение)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf_es = GradientBoostingClassifier(n_iter_no_change=5, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf_es.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_y_pred = gb_clf_es.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, es_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнивая метрики, какой алгоритм оказался лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
